{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bayesian inference using first trained policy\"\"\"\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import gym\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PyQt5\n",
    "\n",
    "import ray\n",
    "try:\n",
    "    from ray.rllib.agents.agent import get_agent_class\n",
    "except ImportError:\n",
    "    from ray.rllib.agents.registry import get_agent_class\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "from flow.core.util import emission_to_csv\n",
    "from flow.utils.registry import make_create_env\n",
    "from flow.utils.rllib import get_flow_params\n",
    "from flow.utils.rllib import get_rllib_config\n",
    "from flow.utils.rllib import get_rllib_pkl\n",
    "\n",
    "EXAMPLE_USAGE = \"\"\"\n",
    "example usage:\n",
    "    python ./visualizer_rllib.py /ray_results/experiment_dir/result_dir 1\n",
    "Here the arguments are:\n",
    "1 - the path to the simulation results\n",
    "2 - the number of the checkpoint\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"policy_0.pkl\", 'rb') as f:\n",
    "    run_transfer = dill.load(f)\n",
    "    args = dill.load(f)\n",
    "    bayesian_1_flow_params = dill.load(f)\n",
    "    create_env = dill.load(f)\n",
    "    create_agent = dill.load(f)\n",
    "    \n",
    "    run_env = dill.load(f)\n",
    "    pr_ped_given_action = dill.load(f)\n",
    "    accel_pdf = dill.load(f)\n",
    "    plot_2_lines = dill.load(f)\n",
    "    requirements = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-27 23:17:06,166\tINFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-03-27_23-17-06_166546_29468/logs.\n",
      "2020-03-27 23:17:06,277\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:50096 to respond...\n",
      "2020-03-27 23:17:06,413\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:27238 to respond...\n",
      "2020-03-27 23:17:06,421\tINFO services.py:809 -- Starting Redis shard with 3.33 GB max memory.\n",
      "2020-03-27 23:17:06,470\tINFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-03-27_23-17-06_166546_29468/logs.\n",
      "2020-03-27 23:17:06,473\tWARNING services.py:1330 -- WARNING: The default object store size of 4.99 GB will use more than 50% of the available memory on this node (8.33 GB). Consider setting the object store memory manually to a smaller size to avoid memory contention with other applications.\n",
      "2020-03-27 23:17:06,474\tINFO services.py:1475 -- Starting the Plasma object store with 4.99 GB memory using /dev/shm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: With render mode sumo_gui, an extra instance of the SUMO GUI will display before the GUI for visualizing the result. Click the green Play arrow to continue.\n",
      "(2.1)--(1.1) (1.1)--(1.2) 1 1\n",
      "Error making env  Cannot re-register id: Bayesian1Env-v0\n",
      "True\n",
      "NOTE: With render mode sumo_gui, an extra instance of the SUMO GUI will display before the GUI for visualizing the result. Click the green Play arrow to continue.\n",
      "(2.1)--(1.1) (1.1)--(1.2) 1 1\n",
      "Error making env  Cannot re-register id: Bayesian1Env-v0\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-27 23:17:09,046\tERROR log_sync.py:34 -- Log sync requires cluster to be setup with `ray up`.\n",
      "2020-03-27 23:17:09,057\tWARNING ppo.py:143 -- FYI: By default, the value function will not share layers with the policy model ('vf_share_layers': False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.1)--(1.1) (1.1)--(1.2) 1 1\n",
      "Error making env  Cannot re-register id: Bayesian1Env-v0\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-27 23:17:10,160\tINFO rollout_worker.py:319 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)\n",
      "2020-03-27 23:17:10,279\tINFO dynamic_tf_policy.py:324 -- Initializing loss function with dummy input:\n",
      "\n",
      "{ 'action_prob': <tf.Tensor 'av/action_prob:0' shape=(?,) dtype=float32>,\n",
      "  'actions': <tf.Tensor 'av/actions:0' shape=(?, 1) dtype=float32>,\n",
      "  'advantages': <tf.Tensor 'av/advantages:0' shape=(?,) dtype=float32>,\n",
      "  'behaviour_logits': <tf.Tensor 'av/behaviour_logits:0' shape=(?, 2) dtype=float32>,\n",
      "  'dones': <tf.Tensor 'av/dones:0' shape=(?,) dtype=bool>,\n",
      "  'new_obs': <tf.Tensor 'av/new_obs:0' shape=(?, 17) dtype=float32>,\n",
      "  'obs': <tf.Tensor 'av/observation:0' shape=(?, 17) dtype=float32>,\n",
      "  'prev_actions': <tf.Tensor 'av/action:0' shape=(?, 1) dtype=float32>,\n",
      "  'prev_rewards': <tf.Tensor 'av/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "  'rewards': <tf.Tensor 'av/rewards:0' shape=(?,) dtype=float32>,\n",
      "  'value_targets': <tf.Tensor 'av/value_targets:0' shape=(?,) dtype=float32>,\n",
      "  'vf_preds': <tf.Tensor 'av/vf_preds:0' shape=(?,) dtype=float32>}\n",
      "\n",
      "/home/thankyou-always/anaconda3/envs/flow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "2020-03-27 23:17:11,087\tINFO rollout_worker.py:742 -- Built policy map: {'av': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x7fb4a8e77630>}\n",
      "2020-03-27 23:17:11,087\tINFO rollout_worker.py:743 -- Built preprocessor map: {'av': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fb4a8e77da0>}\n",
      "2020-03-27 23:17:11,088\tINFO rollout_worker.py:356 -- Built filter map: {'av': <ray.rllib.utils.filter.NoFilter object at 0x7fb4a8e77b00>}\n",
      "2020-03-27 23:17:11,091\tWARNING util.py:47 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Observation outside expected value range', Box(17,), array([ 0.,  0.,  1., 20.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7b22c1db6991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrun_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-d0b16e930f28>\u001b[0m in \u001b[0;36mrun_transfer\u001b[0;34m(args)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-4a99b96eaddf>\u001b[0m in \u001b[0;36mrun_env\u001b[0;34m(env, agent, config, flow_params)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flow/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36mcompute_action\u001b[0;34m(self, observation, state, prev_action, prev_reward, info, policy_id, full_fetch)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         preprocessed = self.workers.local_worker().preprocessors[\n\u001b[0;32m--> 563\u001b[0;31m             policy_id].transform(observation)\n\u001b[0m\u001b[1;32m    564\u001b[0m         filtered_obs = self.workers.local_worker().filters[policy_id](\n\u001b[1;32m    565\u001b[0m             preprocessed, update=False)\n",
      "\u001b[0;32m~/anaconda3/envs/flow/lib/python3.6/site-packages/ray/rllib/models/preprocessors.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPreprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flow/lib/python3.6/site-packages/ray/rllib/models/preprocessors.py\u001b[0m in \u001b[0;36mcheck_shape\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     raise ValueError(\n\u001b[1;32m     60\u001b[0m                         \u001b[0;34m\"Observation outside expected value range\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                         self._obs_space, observation)\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: ('Observation outside expected value range', Box(17,), array([ 0.,  0.,  1., 20.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]))"
     ]
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()\n",
    "run_transfer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
