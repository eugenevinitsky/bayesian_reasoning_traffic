{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Infer pedestrian presence using PPO policy\"\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import gym\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import PyQt5\n",
    "import psutil\n",
    "\n",
    "import ray\n",
    "try:\n",
    "    from ray.rllib.agents.agent import get_agent_class\n",
    "except ImportError:\n",
    "    from ray.rllib.agents.registry import get_agent_class\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "# from flow.algorithms.maddpg.maddpg import DEFAULT_CONFIG as MADDPG_DEFAULT_CONFIG, MADDPGTrainer\n",
    "\n",
    "# from examples.rllib.multiagent_exps.test_predictor.pedestrian_policy_1 import create_env, create_agent\n",
    "# from examples.rllib.multiagent_exps.bayesian_0_no_grid_env import make_flow_params as bayesian_1_flow_params\n",
    "from examples.rllib.multiagent_exps.test_predictor.rule_based_config import make_env as create_env\n",
    "from examples.rllib.multiagent_exps.test_predictor.rule_based_config import get_flow_params as bayesian_1_flow_params\n",
    "\n",
    "from flow.core.util import emission_to_csv\n",
    "from flow.utils.rllib import get_flow_params\n",
    "from flow.utils.rllib import get_rllib_config\n",
    "from flow.utils.rllib import get_rllib_pkl\n",
    "\n",
    "# from examples.rllib.multiagent_exps.test_predictor.pedestrian_policy_1 import create_agent\n",
    "# from get_agent import get_inference_network\n",
    "# \n",
    "\n",
    "EXAMPLE_USAGE = \"\"\"\n",
    "example usage:\n",
    "    python ./visualizer_rllib.py /ray_results/experiment_dir/result_dir 1\n",
    "Here the arguments are:\n",
    "1 - the path to the simulation results\n",
    "2 - the number of the checkpoint\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Math\n",
    "\n",
    "$$ p(c|a) = \\frac{f(a|c) p(c)}{C}, C = \\sum_{e \\in every} f(a | e) p(e), c \\text{ is some joint ped combination}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code flow\n",
    "\n",
    "e denotes an element within the 'every' set, where 'every' = the set of all possible pedestrian location combinations observable by a vehicle\n",
    "\n",
    "o denotes an element with the 'other' set, where 'other' = the set of all possible pedestrian location combinations observable by a vehicle, where $o_1 = 1$ or some other specific location has a fixed value.\n",
    " \n",
    "0. Fill up $p(e)$ with $\\frac{1}{3^4}$\n",
    "\n",
    "1. Fill up $f(a|e)$\n",
    "\n",
    "2. Compute $C = \\sum_{e \\in every} f(a|e) p(e)$\n",
    "\n",
    "3. Compute $p(e|a) = \\frac{f(a|e) p(e)}{C}$ \n",
    "\n",
    "4. Update $p(e) = p(e|a)$\n",
    "\n",
    "5. Compute $p(o_i = b_i | a) = \\sum_{o \\in other} p(o|a)$\n",
    "\n",
    "6. Store $p(o_i = b_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The keys 'ij' mean transition from state i to state j\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{0: {'00': 164579, '01': 107, '10': 107, '11': 14516}, \n",
    " 1: {'00': 163013, '01': 123, '10': 123, '11': 16050}, \n",
    " 2: {'00': 161202, '01': 134, '10': 134, '11': 17839}, \n",
    " 3: {'00': 164743, '01': 112, '10': 112, '11': 14342}}\n",
    "\n",
    "\"The keys 'ij' mean transition from state i to state j\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(ped_{t} | ped_{t-1}) = 14516 / (107 + 14516)\n",
    "\n",
    "p(ped_{t} | no_ped_{t-1}) = 107 / (107 + 164579)\n",
    "\n",
    "p(no_ped_{t} | ped_{t-1}) = 107 / (107 + 14516)\n",
    "\n",
    "p(no_ped_{t} | no_ped_{t-1}) = 164579 / (164579 + 107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = 14516 / (107 + 14516)\n",
    "pno = 107 / (107 + 164579)\n",
    "nop = 107 / (107 + 14516)\n",
    "nono = 164579 / (164579 + 107)\n",
    "\n",
    "a = np.array([nono, pno])\n",
    "b = np.array([nop, pp])\n",
    "\n",
    "TRANSITION_MATRIX = np.array([a, b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert constants to uppercase\n",
    "K = 5\n",
    "NOISE_STD = 0.01\n",
    "ped_idx_lst = [10, 11, 12, 13]\n",
    "ped_front = ped_idx_lst[0]\n",
    "ped_back = ped_idx_lst[-1]\n",
    "\n",
    "num_locs = 4\n",
    "# flag_set = (\"-1\", \"0\", \"1\")\n",
    "flag_set = (\"0\", \"1\")\n",
    "\n",
    "def run_env(env, agent, flow_params, is_discrete, rule_based):\n",
    "    \"\"\"Run the simulation and control the rl car using the trained policy. \n",
    "    \n",
    "    observation[4:10] = ped_param\n",
    "    \n",
    "    The six binary grids are at indices 4 to 9 inclusive\n",
    "    \"\"\"\n",
    "#     # set up relevant policy and env\n",
    "#     if config.get('multiagent', {}).get('policies', None):\n",
    "#         multiagent = True\n",
    "#         rets = {}\n",
    "#         # map the agent id to its policy\n",
    "#         policy_map_fn = config['multiagent']['policy_mapping_fn']\n",
    "#         for key in config['multiagent']['policies'].keys():\n",
    "#             rets[key] = []\n",
    "#     else:\n",
    "#         multiagent = False\n",
    "#         rets = []\n",
    "# #     import ipdb;ipdb.set_trace()\n",
    "#     if config['model']['use_lstm']:\n",
    "#         use_lstm = True\n",
    "#         if multiagent:\n",
    "#             state_init = {}\n",
    "#             policy_map_fn = config['multiagent']['policy_mapping_fn']\n",
    "#             size = config['model']['lstm_cell_size']\n",
    "#             for key in config['multiagent']['policies'].keys():\n",
    "#                 state_init[key] = [np.zeros(size, np.float32),\n",
    "#                                    np.zeros(size, np.float32)]\n",
    "#         else:\n",
    "#             state_init = [\n",
    "#                 np.zeros(config['model']['lstm_cell_size'], np.float32),\n",
    "#                 np.zeros(config['model']['lstm_cell_size'], np.float32)\n",
    "#             ]\n",
    "#     else:\n",
    "#         use_lstm = False\n",
    "\n",
    "    env.restart_simulation(\n",
    "        sim_params=flow_params['sim'], render=flow_params['sim'].render) \n",
    "    render = True\n",
    "    env.should_render = render\n",
    "    flow_params['sim'].render = render\n",
    "    env.restart_simulation(\n",
    "        sim_params=flow_params['sim'], render=render)      \n",
    "\n",
    "    binary_observations = False\n",
    "    \n",
    "    # Permutation lists\n",
    "    joint_ped_combos_str = all_ped_combos_strs(num_locs, flag_set)\n",
    "    joint_ped_combos_int_list = all_ped_combos_lsts(num_locs, flag_set)\n",
    "    single_ped_combs_str = single_ped_posteriors_strs(num_locs, flag_set)\n",
    "    \n",
    "    ################\n",
    "    # Dictionaries #\n",
    "    ################\n",
    "    \n",
    "    # 1\n",
    "    single_priors_fixed = {comb : [1 / len(flag_set)] for comb in single_ped_combs_str} \n",
    "    single_priors_updated = {comb : [1 / len(flag_set)] for comb in single_ped_combs_str}\n",
    "\n",
    "    # 2\n",
    "    joint_likelihood_densities = {comb : [] for comb in joint_ped_combos_str}\n",
    "    \n",
    "    # 3\n",
    "    joint_priors_fixed = {comb : [1 / (len(flag_set)**num_locs)] for comb in joint_ped_combos_str}\n",
    "    joint_priors_updated = {comb : [1 / (len(flag_set)**num_locs)] for comb in joint_ped_combos_str}\n",
    "    \n",
    "    # 5 \n",
    "    joint_posteriors_fixed = {comb : [] for comb in joint_ped_combos_str}\n",
    "    joint_posteriors_updated = {comb : [] for comb in joint_ped_combos_str}\n",
    "    \n",
    "    # 6 \n",
    "    single_posteriors_fixed = {comb : [] for comb in single_ped_combs_str}\n",
    "    single_posteriors_updated = {comb : [] for comb in single_ped_combs_str}\n",
    "    \n",
    "    \n",
    "    # 1 Filter\n",
    "    single_priors_filter = {comb : [1 / len(flag_set)] for comb in single_ped_combs_str}\n",
    "    \n",
    "    # 3 Filter\n",
    "    joint_priors_filter = {comb : [1 / (len(flag_set)**num_locs)] for comb in joint_ped_combos_str}\n",
    "\n",
    "    # 5 Filter\n",
    "    joint_posteriors_filter = {comb : [] for comb in joint_ped_combos_str}\n",
    "    \n",
    "    # 6 Filter\n",
    "    single_posteriors_filter = {comb : [] for comb in single_ped_combs_str} \n",
    "        \n",
    "    \n",
    "    # 5 Updated K\n",
    "    single_posteriors_updated_K = {comb : [] for comb in single_ped_combs_str}\n",
    "\n",
    "    visible_pedestrian_dct = {loc : [] for loc in range(num_locs)}\n",
    "    intersection_status = []\n",
    "    \n",
    "#     sigma_vals = []\n",
    "#     mean_vals = []\n",
    "    action_vals = []\n",
    "\n",
    "    action_pairs = []\n",
    "    \n",
    "    ####################\n",
    "    # Step through env #\n",
    "    ####################\n",
    "    \n",
    "    for i in range(args.num_rollouts):\n",
    "        state = env.reset()\n",
    "        for time in range(600):\n",
    "            vehicles = env.unwrapped.k.vehicle\n",
    "            pedestrian = env.unwrapped.k.pedestrian\n",
    "            multiagent = True\n",
    "            if multiagent:                \n",
    "                action, logits = {}, {}\n",
    "                # TODO(@evinitsky) make more general\n",
    "                agent_ids = ['rl_0']\n",
    "                for agent_id in agent_ids:\n",
    "                    use_lstm = False\n",
    "                    if use_lstm:   # we don't use lstm\n",
    "                        action[agent_id], state_init[agent_id], logits = \\\n",
    "                            agent.get_accel_gaussian_params_from_observation(state[agent_id])\n",
    "                    else:\n",
    "                        if state != {} and agent_id in state.keys() and agent_id not in env.k.vehicle.get_arrived_ids():\n",
    "                            \n",
    "#                             print(psutil.virtual_memory())\n",
    "                            \n",
    "#                             if t > 30:\n",
    "#                                 for loc_ in range(num_locs):\n",
    "#                                     for val_ in flag_set:\n",
    "#                                         single_posterior_str = f'o_{loc_} = {val_}'\n",
    "#                                         print(len(single_priors_fixed[single_posterior_str]))\n",
    "#                                         print(len(single_priors_updated[single_posterior_str]))\n",
    "#                                         print(len(single_priors_filter[single_posterior_str]), 111) \n",
    "#                                         print(single_priors_filter[single_posterior_str])\n",
    "#                                         print(len(single_posteriors_filter[single_posterior_str]))\n",
    "#                                         print(len(single_posteriors_updated_K[single_posterior_str])) \n",
    "#                                         print(len(single_posteriors_fixed[single_posterior_str]))\n",
    "#                                         print(len(single_posteriors_updated[single_posterior_str]))\n",
    "#                                 for str_comb in joint_ped_combos_str:\n",
    "#                                     print(len(joint_priors_filter[str_comb]))\n",
    "#                                     print(len(joint_posteriors_filter[str_comb]))\n",
    "#                                     print(len(joint_likelihood_densities[str_comb]))\n",
    "#                                     print(len(joint_priors_fixed[str_comb]))\n",
    "#                                     print(len(joint_priors_updated[str_comb]))\n",
    "#                                     print(len(joint_posteriors_fixed[str_comb]))\n",
    "#                                     print(len(joint_posteriors_updated[str_comb]))\n",
    "\n",
    "                            \n",
    "                            # s_all = state the agent observes\n",
    "                            s_all = state[agent_id]\n",
    "                            # get ped visibility state array of length 6 from the rl car's POV\n",
    "                            s_ped = s_all[ped_idx_lst]\n",
    "\n",
    "                            # update the visible_pedestrian dict\n",
    "                            for idx, val in enumerate(s_ped):\n",
    "                                visible_pedestrian_dct[idx] = visible_pedestrian_dct[idx] + [val]\n",
    "\n",
    "                            # update rl car's intersection status\n",
    "                            rt = vehicles.get_route('rl_0')\n",
    "                            if len(rt) > 0:\n",
    "                                if vehicles.get_edge('rl_0') == rt[0]:\n",
    "                                    intersection_status.append(-1)\n",
    "                                elif vehicles.get_edge('rl_0') == rt[-1]:\n",
    "                                    intersection_status.append(1)\n",
    "                                else:\n",
    "                                    intersection_status.append(0)\n",
    "                                             \n",
    "                            # compute the actual action taken by the rl car\n",
    "#                             action[agent_id], _, logit_actual = agent.compute_action(state[agent_id], policy_id=policy_map_fn(agent_id), full_fetch=True)    \n",
    "                            if is_discrete:\n",
    "        \n",
    "                                action_index = env.k.vehicle.get_acc_controller(agent_id).get_discrete_action(env)\n",
    "                            try:\n",
    "                                action_ = env.k.vehicle.get_acc_controller(agent_id).get_accel(env)\n",
    "                            except:\n",
    "                                import ipdb; ipdb.set_trace()\n",
    "                            \n",
    "                            # we are not in control so skip this step\n",
    "                            if action_ is None:\n",
    "#                                 action_ = 3.0\n",
    "                                continue\n",
    "                            \n",
    "#                             mu, ln_sigma = logit_actual['behaviour_logits']\n",
    "#                             sigma = np.exp(ln_sigma)\n",
    "                            \n",
    "#                             sigma_vals.append(sigma)\n",
    "#                             mean_vals.append(mu)\n",
    "                            action_vals.append(action_)\n",
    "                            \n",
    "                            if action_pairs == []:\n",
    "                                action_pairs.append([action_])\n",
    "                            else:\n",
    "                                action_pairs[-1].append(action_)\n",
    "                                action_pairs.append([action_])\n",
    "                                                            \n",
    "\n",
    "                            # 2 f(a|e) # 4 M\n",
    "                            M_updated, M_fixed, M_filter = 0, 0, 0\n",
    "                            \n",
    "                            for str_comb, lst_comb in zip(joint_ped_combos_str, joint_ped_combos_int_list):\n",
    "\n",
    "                                s_all_modified = np.copy(s_all) # s_all_modified = hypothetical state that an agent observes\n",
    "                                s_all_modified[ped_idx_lst] = lst_comb\n",
    "#                                 _, _, logit = agent.compute_action(s_all_modified, policy_id=policy_map_fn(agent_id), full_fetch=True)\n",
    "                                if rule_based:\n",
    "                                    mu = env.k.vehicle.get_acc_controller(agent_id).get_action_with_ped(env, s_all_modified)\n",
    "                                    sigma = NOISE_STD\n",
    "                                    # noise up your model\n",
    "                                    if sigma > 0.0:\n",
    "                                        mu += np.random.normal(loc=0.0, scale=sigma)\n",
    "                                    joint_likelihood_density = accel_pdf(mu, sigma, action_)\n",
    "                                else:\n",
    "                                    if is_discrete:\n",
    "                                        _, _, logit = agent.compute_action(s_all_modified, policy_id='av', full_fetch=True)\n",
    "\n",
    "    #                                     max_index = np.argmax(logit['q_values'])\n",
    "    #                                     joint_likelihood_density = max_index == action_index\n",
    "                                        q_vals = logit['q_values']\n",
    "                                        soft_max = scipy.special.softmax(q_vals)\n",
    "                                        joint_likelihood_density = soft_max[action_index]\n",
    "                                    else:\n",
    "                                        mu, sigma = agent.get_accel_gaussian_params_from_observation(s_all_modified)\n",
    "                                        sigma = sigma[0]\n",
    "        #                                 mu, ln_sigma = logit['behaviour_logits']\n",
    "        #                                 sigma = np.exp(ln_sigma)\n",
    "\n",
    "                                        # f(a|e)\n",
    "                                        joint_likelihood_density = accel_pdf(mu, sigma, action_)[0]\n",
    "                                joint_likelihood_densities[str_comb].append(joint_likelihood_density)\n",
    "\n",
    "                                # M\n",
    "                                # Get p(e)\n",
    "                                updated_prior = joint_priors_updated[str_comb][-1]\n",
    "                                fixed_prior = joint_priors_fixed[str_comb][-1]\n",
    "                                filtered_prior = joint_priors_filter[str_comb][-1]\n",
    "\n",
    "                                M_updated += joint_likelihood_density * updated_prior\n",
    "                                M_fixed += joint_likelihood_density * fixed_prior\n",
    "                                M_filter += joint_likelihood_density * filtered_prior\n",
    "\n",
    "                            # 5 p(e|a) joint posterior masses\n",
    "                            for str_comb in joint_ped_combos_str:\n",
    "                                # f(a|e)\n",
    "                                joint_likelihood_density = joint_likelihood_densities[str_comb][-1]\n",
    "                                # p(e)\n",
    "                                updated_prior = joint_priors_updated[str_comb][-1]\n",
    "                                fixed_prior = joint_priors_fixed[str_comb][-1]\n",
    "                                filtered_prior = joint_priors_filter[str_comb][-1]\n",
    "\n",
    "                                # p(e|a)\n",
    "                                joint_posterior_updated = joint_likelihood_density * updated_prior / M_updated\n",
    "                                joint_posterior_fixed = joint_likelihood_density * fixed_prior / M_fixed\n",
    "                                joint_posterior_filtered = joint_likelihood_density * filtered_prior / M_filter\n",
    "\n",
    "                                joint_posteriors_updated[str_comb].append(joint_posterior_updated)\n",
    "                                joint_posteriors_fixed[str_comb].append(joint_posterior_fixed)\n",
    "                                joint_posteriors_filter[str_comb].append(joint_posterior_filtered)\n",
    "\n",
    "                            # 6 & 7\n",
    "                            for loc_ in range(num_locs):\n",
    "                                for val_ in flag_set:\n",
    "\n",
    "                                    single_posterior_updated = 0\n",
    "                                    single_posterior_fixed = 0\n",
    "                                    single_posterior_filter = 0\n",
    "\n",
    "                                    for key in ped_combos_one_loc_fixed_strs(loc_, val_):\n",
    "                                        single_posterior_updated += joint_posteriors_updated[key][-1]\n",
    "                                        single_posterior_fixed += joint_posteriors_fixed[key][-1]\n",
    "                                        single_posterior_filter += joint_posteriors_filter[key][-1]\n",
    "\n",
    "                                    single_posterior_str = f'o_{loc_} = {val_}'\n",
    "\n",
    "                                    single_posteriors_updated[single_posterior_str].append(single_posterior_updated)\n",
    "                                    \n",
    "                                    if len(joint_priors_updated[\"1 1 1 1\"]) < K: \n",
    "                                        single_posteriors_updated_K[single_posterior_str].append(single_posterior_updated)\n",
    "                                   \n",
    "                                    single_posteriors_fixed[single_posterior_str].append(single_posterior_fixed)\n",
    "                                    single_posteriors_filter[single_posterior_str].append(single_posterior_filter)\n",
    "                                    \n",
    "                                    # 7\n",
    "                                    single_priors_fixed[single_posterior_str].append(single_posterior_fixed)\n",
    "                                    single_priors_updated[single_posterior_str].append(single_posterior_updated)\n",
    "                                    \n",
    "                            # FILTER (part after step 6: filter p(o|a))\n",
    "                            for loc_ in range(num_locs):\n",
    "                                val0, val1 = \"0\", \"1\"\n",
    "                                single_0 = f'o_{loc_} = {val0}'\n",
    "                                single_1 = f'o_{loc_} = {val1}'\n",
    "                                try:\n",
    "                                    filtered = TRANSITION_MATRIX @ np.array([single_posteriors_filter[single_0][-1], single_posteriors_filter[single_1][-1]])\n",
    "                                except:\n",
    "                                    import ipdb; ipdb.set_trace()\n",
    "                                single_posteriors_filter[single_0][-1], single_posteriors_filter[single_1][-1] = filtered[0], filtered[1]\n",
    "\n",
    "                           # 7 Filter Update single priors Pr(o_i | a) using posteriors\n",
    "                            for loc_ in range(num_locs):\n",
    "                                for val_ in flag_set:\n",
    "                                    single_prior_str = f'o_{loc_} = {val_}'\n",
    "                                    single_priors_filter[single_prior_str].append(single_posteriors_filter[single_prior_str][-1])\n",
    "\n",
    "                            # 8 Update joint priors p(o|a) = \\prod_{o_i \\in o} p(o_i)\n",
    "                            for str_comb in joint_ped_combos_str:\n",
    "                                new_joint_prior_updated = 1\n",
    "                                new_joint_prior_fixed = 1\n",
    "\n",
    "                                single_ped_lst = joint_ped_combo_str_to_single_ped_combo(str_comb)\n",
    "                                for single_ped in single_ped_lst:\n",
    "                                    new_joint_prior_updated *= single_posteriors_updated[single_ped][-1]\n",
    "\n",
    "                                joint_priors_updated[str_comb].append(new_joint_prior_updated)\n",
    "\n",
    "                            # 8 FILTER Update joint priors p(o|a) = \\prod_{o_i \\in o} p(o_i)\n",
    "                            for str_comb in joint_ped_combos_str:\n",
    "                                new_joint_prior_filter = 1\n",
    "\n",
    "                                single_ped_lst = joint_ped_combo_str_to_single_ped_combo(str_comb)\n",
    "\n",
    "                                for single_ped in single_ped_lst:\n",
    "                                    new_joint_prior_filter *= single_priors_filter[single_ped][-1]\n",
    "\n",
    "                                joint_priors_filter[str_comb].append(new_joint_prior_filter)\n",
    "    \n",
    "    \n",
    "                            ############            \n",
    "                            # K update #\n",
    "                            ############\n",
    "                \n",
    "                            if len(joint_likelihood_densities[\"1 1 1 1\"]) >= K:\n",
    "                                joint_priors_updated_K = {comb : [1 / (len(flag_set)**num_locs)] for comb in joint_ped_combos_str}\n",
    "\n",
    "                                for str_comb, lst_comb in zip(joint_ped_combos_str, joint_ped_combos_int_list):\n",
    "\n",
    "                                    s_all_modified = np.copy(s_all) # s_all_modified = hypothetical state that an agent observes\n",
    "                                    s_all_modified[ped_front : ped_back + 1] = lst_comb\n",
    "# #                                     _, _, logit = agent.compute_action(s_all_modified, policy_id=policy_map_fn(agent_id), full_fetch=True)\n",
    "\n",
    "#                                     mu, ln_sigma = logit['behaviour_logits']\n",
    "#                                     sigma = np.exp(ln_sigma)\n",
    "                                if rule_based:\n",
    "                                    mu = env.k.vehicle.get_acc_controller(agent_id).get_action_with_ped(env, s_all_modified)\n",
    "                                    sigma = NOISE_STD\n",
    "                                else:\n",
    "                                    if not is_discrete:\n",
    "                                        mu, sigma = agent.get_accel_gaussian_params_from_observation(s_all_modified)\n",
    "                                        sigma = sigma[0]\n",
    "\n",
    "                                # update joint prior masses\n",
    "                                for i in reversed(range(K)):\n",
    "                                    M_updated_K = 0\n",
    "                                    for str_comb in joint_ped_combos_str:\n",
    "                                        M_updated_K += joint_likelihood_densities[str_comb][-1 - i] * joint_priors_updated_K[str_comb][-1]\n",
    "                                    for str_comb in joint_ped_combos_str:\n",
    "                                        joint_likelihood_density = joint_likelihood_densities[str_comb][-1 - i] # f(a|c)\n",
    "                                        joint_prior_updated = joint_priors_updated_K[str_comb][-1] # p(c)\n",
    "                \n",
    "                                        joint_priors_updated_K[str_comb].append(joint_likelihood_density * joint_prior_updated / M_updated_K)\n",
    "                                    \n",
    "                                # 5 Compute single posteriors Pr(o_i = b_i | a)\n",
    "                                for loc__ in range(num_locs):\n",
    "                                    for val__ in flag_set:\n",
    "\n",
    "                                        single_posterior_updated = 0\n",
    "\n",
    "                                        for key in ped_combos_one_loc_fixed_strs(loc__, val__):\n",
    "                                            single_posterior_updated += joint_priors_updated_K[key][-1]\n",
    "\n",
    "                                        single_posterior_str = f'o_{loc__} = {val__}'\n",
    "                                        single_posteriors_updated_K[single_posterior_str].append(single_posterior_updated)\n",
    "\n",
    "            else:\n",
    "                action = agent.compute_action(state)\n",
    "\n",
    "            state, reward, done, _ = env.step(None)\n",
    "\n",
    "            if multiagent and done['__all__']:\n",
    "                break\n",
    "            if not multiagent and done:\n",
    "\n",
    "                break    \n",
    "#             state, reward, done, _ = env.step(action)   \n",
    "\n",
    "    visible_ped_lsts = [visible_pedestrian_dct[i] for i in range(num_locs)]\n",
    "    legends = [f'ped at loc {i}' for i in range(num_locs)]\n",
    "\n",
    "    \n",
    "    for loc in range(num_locs):\n",
    "        for val in [0, 1]:\n",
    "            single_posterior_str = single_posterior_to_str(loc, val)\n",
    "            a_ = single_posteriors_updated[single_posterior_str]\n",
    "            b_ = single_posteriors_fixed[single_posterior_str]\n",
    "            c_ = single_posteriors_updated_K[single_posterior_str]\n",
    "            d_ = single_posteriors_filter[single_posterior_str]\n",
    "            plot_2_lines(a_, b_, [f'Pr(ped in grid {loc} = {val}) using updated priors K = all', f'Pr(ped in grid {loc} = {val}) using fixed priors'])\n",
    "            plot_2_lines(c_, b_, [f'Pr(ped in grid {loc} = {val}) using updated priors K = 5', f'Pr(ped in grid {loc} = {val}) using fixed priors'])\n",
    "            plot_2_lines(d_, b_, [f'Pr(ped in grid {loc} = {val}) using filtered priors', f'Pr(ped in grid {loc} = {val}) using fixed priors'])\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    y0 = visible_pedestrian_dct[0]\n",
    "    y1 = visible_pedestrian_dct[1]\n",
    "    y2 = visible_pedestrian_dct[2]\n",
    "    y3 = visible_pedestrian_dct[3]\n",
    "\n",
    "    vis_ped_0 = plt.subplot(2, 4, 1)\n",
    "    plt.plot(y0, 'o-')\n",
    "    vis_ped_0.set_title('Pedestrian in loc 0')\n",
    "    vis_ped_0.set_xlabel('time (s)')\n",
    "    vis_ped_0.set_ylabel('in loc 1?')\n",
    "    vis_ped_0.set_ylim([-1, 1])\n",
    "\n",
    "    vis_ped_1 = plt.subplot(2, 4, 2)\n",
    "    plt.plot(y1, 'o-')\n",
    "    vis_ped_1.set_title('Pedestrian in loc 1')\n",
    "    vis_ped_1.set_xlabel('time (s)')\n",
    "    vis_ped_1.set_ylabel('in loc 1?')\n",
    "    vis_ped_1.set_ylim([-1, 1])\n",
    "\n",
    "    vis_ped_2 = plt.subplot(2, 4, 3)\n",
    "    vis_ped_2.plot(y2, '.-')\n",
    "    vis_ped_2.set_title('Pedestrian in loc 2')\n",
    "\n",
    "    vis_ped_2.set_xlabel('time (s)')\n",
    "    vis_ped_2.set_ylabel('in loc 2?')\n",
    "    vis_ped_2.set_ylim([-1, 1])\n",
    "\n",
    "\n",
    "    vis_ped_3 = plt.subplot(2, 4, 4)\n",
    "    vis_ped_3.plot(y3, '.-')\n",
    "    vis_ped_3.set_title('Pedestrian in loc 3')\n",
    "\n",
    "    vis_ped_3.set_xlabel('time (s)')\n",
    "    vis_ped_3.set_ylabel('in loc 3?')\n",
    "    vis_ped_3.set_ylim([-1, 1])\n",
    "\n",
    "    print(intersection_status, len(intersection_status))\n",
    "    intersection = plt.subplot(2, 4, 5)\n",
    "    intersection.plot(intersection_status)\n",
    "    intersection.set_title('-1 = approaching, 0 = on intersection, 1 = past')\n",
    "    intersection.set_xlabel('time (s)')\n",
    "    intersection.set_ylabel('rl car location')\n",
    "    intersection.set_ylim([-1, 1])\n",
    "    \n",
    "#     sigma = plt.subplot(2, 4, 6)\n",
    "#     sigma.plot(sigma_vals)\n",
    "#     sigma.set_title('Sigma')\n",
    "#     sigma.set_xlabel('time (s)')\n",
    "#     sigma.set_ylabel('sigma')\n",
    "    \n",
    "#     mean = plt.subplot(2, 4, 7)\n",
    "#     mean.plot(mean_vals)\n",
    "#     mean.set_title('Mean')\n",
    "#     mean.set_xlabel('time (s)')\n",
    "#     mean.set_ylabel('mean')\n",
    "    \n",
    "    x = np.array(action_vals)\n",
    "    x1 = x[1:]\n",
    "    x2 = x[:-1]\n",
    "    xx = np.stack([x1, x2])\n",
    "    print(np.cov(xx))\n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String and permutation helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_ped_combo_str_to_single_ped_combo(joint_ped_combo_str):\n",
    "    \"\"\"Given a string of format '0 1 0 -1', return a list of all relevant single ped strings\n",
    "    i.e ['o_0 = 0', 'o_1 = 1', 'o_2 = 0', 'o_3 = -1']\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    jnt_ped_list = joint_ped_combo_str.split(\" \")\n",
    "    for loc, val in enumerate(jnt_ped_list):\n",
    "        res.append(single_posterior_to_str(loc, val))\n",
    "    return res\n",
    "\n",
    "def single_posterior_to_str(loc, val):\n",
    "    return f'o_{loc} = {val}'\n",
    "\n",
    "def all_ped_combos_strs(num_locs=4, val_set=(\"0\", \"1\")):\n",
    "    \"\"\"Return a list of all pedestrian observation combinations (in string format) for a vehicle under the 4 location scheme\"\"\"\n",
    "    res = []\n",
    "    lsts = all_ped_combos_lsts(num_locs, val_set)\n",
    "    for lst in lsts:\n",
    "        res.append(\" \".join(lst))\n",
    "    return res\n",
    "\n",
    "def all_ped_combos_lsts(num_locs=4, val_set=(\"0\", \"1\")):\n",
    "    \"\"\"Return a list of all pedestrian observation combinations (in list format) for a vehicle under the 4 location scheme\"\"\"\n",
    "    res = []\n",
    "    if num_locs == 0:\n",
    "        return []\n",
    "    if num_locs == 1:\n",
    "        return [[flag] for flag in val_set]\n",
    "\n",
    "    for comb in all_ped_combos_lsts(num_locs - 1, val_set):\n",
    "        # append a flag for all possible flags\n",
    "        for flag in val_set:\n",
    "            appended = comb + [flag]\n",
    "            res.append(appended)\n",
    "            \n",
    "    return res\n",
    "\n",
    "def ped_combos_one_loc_fixed_strs(fixed_loc, fixed_val, num_locs=4, val_set=(\"0\", \"1\")):\n",
    "    \"\"\"Return a list of all ped observation combs for a vehicle under the 4 location scheme\n",
    "    SUBJECT TO fixed_loc == fix_val\n",
    "    \n",
    "    This is handy for summation selection in equation (4) of the derivation\n",
    "    \n",
    "    @Parameters\n",
    "    fixed_loc: int\n",
    "        location from 0, 1, 2, 3\n",
    "    fixed_val: int\n",
    "        location from -1, 0, 1\n",
    "    \"\"\"    \n",
    "    res = []\n",
    "    lsts = ped_combos_one_loc_fixed_lsts(fixed_loc, fixed_val, num_locs, val_set)\n",
    "    for lst in lsts:\n",
    "        res.append(\" \".join(lst))\n",
    "    return res\n",
    "\n",
    "def ped_combos_one_loc_fixed_lsts(fixed_loc, fixed_val, num_locs=4, val_set=(\"0\", \"1\")):\n",
    "    \"\"\"Return a list of all ped observation combs for a vehicle under the 4 location scheme\n",
    "    SUBJECT TO fixed_loc == fix_val\n",
    "    \n",
    "    This is handy for summation selection in equation (4) of the derivation\n",
    "    \n",
    "    @Parameters\n",
    "    fixed_loc: int\n",
    "        location from 0, 1, 2, 3\n",
    "    fixed_val: int\n",
    "        location from -1, 0, 1\n",
    "    \"\"\"\n",
    "    fixed_val = str(fixed_val)\n",
    "    assert fixed_loc < num_locs and (fixed_val in val_set or str(fixed_val) in val_set)\n",
    "    \n",
    "    res = []\n",
    "    for comb in all_ped_combos_lsts(num_locs - 1, val_set):\n",
    "        # insert fixed val at correct position\n",
    "        left = comb[:fixed_loc]\n",
    "        right = comb[fixed_loc:]\n",
    "        res.append(left + [fixed_val] + right)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def single_cond_prob_to_str(grid_idx, val, num_indices = 6):\n",
    "    \"\"\"Generate the string representing the probability:\n",
    "    \n",
    "    Pr(o_i = val)\n",
    "    \n",
    "    ex:\n",
    "    For Pr(o_2 = 1), we'd have the string '21'\n",
    "    NB we're 1-indexing here\n",
    "    \"\"\"\n",
    "    assert grid_idx >= 1 and grid_idx <= num_indices\n",
    "    return str(grid_idx) + str(val)\n",
    "\n",
    "# better name for this? \n",
    "def ped_combos_for_single_cond_prob(grid_idx, val, output_len=6):\n",
    "    \"\"\"Helper function for computing a 'single' conditional probability e.g. p(o_3 = 1 | action)\n",
    "    Returns a list of pedestrian combinations to sum over to get the single conditional probability.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    grid_idx: int from 1 to 6 representing the grid cell we're considering\n",
    "    val: 0 or 1: 0 means no ped in the grid; 1 means ped in the grid\n",
    "    \n",
    "    3:0 means we want p(o_3 = 0 | a)\n",
    "    Therefore, we can get the list of all possible length 5 bitstrings, and stitch '0' in the correct place.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of bit strings of length 6\n",
    "    \"\"\"\n",
    "    \n",
    "    assert grid_idx >= 1 and grid_idx <= output_len\n",
    "    res = []\n",
    "    res_lst = make_permutations(output_len - 1, 2)\n",
    "    \n",
    "    for perm in res_lst:\n",
    "        res.append(str(perm[:grid_idx - 1:] + str(val) + perm[grid_idx - 1:]))\n",
    "        \n",
    "    return res\n",
    "\n",
    "def initial_prior_probs(num_digits=4, vals_per_dig=2):\n",
    "    \"\"\"Returns a dict with values of all permutations of bitstrings of length num_digits. \n",
    "    Each digit can take a value from 0 to (vals_per_dig - 1)\"\"\"\n",
    "    uniform_prob = 1 / (vals_per_dig ** num_digits)\n",
    "    res = make_dct_of_lsts(num_digits, vals_per_dig)\n",
    "    for key in res.keys():\n",
    "        res[key] = res[key] + [uniform_prob]\n",
    "    return res\n",
    "\n",
    "def make_dct_of_lsts(num_digits=4, vals_per_dig=2):\n",
    "    \"\"\"Return a dict with keys of bitstrings and values as empty lists. \n",
    "    Hardcoded for binary vals per var.\"\"\"\n",
    "    res = {}\n",
    "    lst_of_bitstrings = make_permutations(num_digits, vals_per_dig)\n",
    "        \n",
    "    return {str_ : [] for str_ in lst_of_bitstrings}\n",
    "\n",
    "def make_permutations(num_digits, vals_per_dig=2):\n",
    "    \"\"\"Make all permutations for a bit string of length num_digits\n",
    "    and vals_per_dig values per digit. Hardcoded for work for binary vals per var\"\"\"\n",
    "    if num_digits == 1:\n",
    "        return [str(i) for i in range(vals_per_dig)]\n",
    "    else:\n",
    "        small_perms = make_permutations(num_digits - 1, vals_per_dig)\n",
    "        # hardcoded for work for binary vals per var\n",
    "        return ['0' + bit_str for bit_str in small_perms] + ['1' + bit_str for bit_str in small_perms]\n",
    "    \n",
    "def single_ped_posteriors_strs(num_variables=4, val_set=(\"0\", \"1\")):\n",
    "    \"\"\"\n",
    "    @Params\n",
    "    num_variables = number of ped locations\n",
    "    \n",
    "    @Returns\n",
    "    list of strings. Strings have the format: 'o_{i}={val}', where val is in val_set\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(num_variables):\n",
    "        for flag in val_set:\n",
    "            res.append(f'o_{i} = {flag}')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accel_pdf(mu, sigma, actual):\n",
    "    \"\"\"Return pdf evaluated at actual acceleration\"\"\"\n",
    "    coeff = 1 / np.sqrt(2 * np.pi * (sigma**2))\n",
    "    exp = -0.5 * ((actual - mu) / sigma)**2\n",
    "    return coeff * np.exp(exp)\n",
    "\n",
    "def run_transfer(args, action_pairs_lst=[], imitation_model=True, is_discrete=False, rule_based=True):\n",
    "    \"\"\"To run inference using the imitation model, set imitation_model True, is_discrete False.\n",
    "    To run DQN inference, set imitation_model = False, is_discrete = True\"\"\"\n",
    "    # run transfer on the bayesian 1 env first\n",
    "    action_pairs_lst = []\n",
    "    bayesian_0_params = bayesian_1_flow_params(args, pedestrians=True, render=False)\n",
    "    env, env_name = create_env(args, bayesian_0_params)\n",
    "    agent = None\n",
    "    if not rule_based: \n",
    "        if imitation_model:\n",
    "            agent = get_inference_network(os.path.abspath(\"../flow/controllers/imitation_learning/model_files/c_test.h5\"), flow_params=bayesian_0_params)\n",
    "        else:\n",
    "            agent, config = create_agent(args, flow_params=bayesian_0_params)\n",
    "    action_pairs_lst = run_env(env, agent, bayesian_0_params, is_discrete, rule_based)\n",
    "    \n",
    "    return action_pairs_lst\n",
    "def plot_2_lines(y1, y2, legend, viewable_ped=False):\n",
    "    x = np.arange(len(y1))\n",
    "    plt.plot(x, y1)\n",
    "    plt.plot(x, y2)\n",
    "    if viewable_ped:\n",
    "        plt.plot(x, viewable_ped)\n",
    "    plt.legend(legend, bbox_to_anchor=(0.5, 1.05), loc=3, borderaxespad=0.)\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)\n",
    "    \n",
    "def plot_lines(y_val_lsts, legends):\n",
    "    assert len(y_val_lsts) == len(legends)\n",
    "    x = np.arange(len(y_val_lsts[0]))\n",
    "    for y_vals in y_val_lsts:\n",
    "        plt.plot(x, y_vals)\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "\n",
    "    plt.legend(legends, bbox_to_anchor=(0.5, 1.05), loc=3, borderaxespad=0.)\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)\n",
    "    \n",
    "def create_parser():\n",
    "    \"\"\"Create the parser to capture CLI arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "        description='[Flow] Evaluates a reinforcement learning agent '\n",
    "                    'given a checkpoint.',\n",
    "        epilog=EXAMPLE_USAGE)\n",
    "\n",
    "    # required input parameters\n",
    "    parser.add_argument(\n",
    "        'result_dir', type=str, help='Directory containing results')\n",
    "    parser.add_argument('checkpoint_num', type=str, help='Checkpoint number.')\n",
    "\n",
    "    # optional input parameters\n",
    "    parser.add_argument(\n",
    "        '--run',\n",
    "        type=str,\n",
    "        help='The algorithm or model to train. This may refer to '\n",
    "             'the name of a built-on algorithm (e.g. RLLib\\'s DQN '\n",
    "             'or PPO), or a user-defined trainable function or '\n",
    "             'class registered in the tune registry. '\n",
    "             'Required for results trained with flow-0.2.0 and before.')\n",
    "    parser.add_argument(\n",
    "        '--num_rollouts',\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help='The number of rollouts to visualize.')\n",
    "    parser.add_argument(\n",
    "        '--gen_emission',\n",
    "        action='store_true',\n",
    "        help='Specifies whether to generate an emission file from the '\n",
    "             'simulation')\n",
    "    parser.add_argument(\n",
    "        '--evaluate',\n",
    "        action='store_true',\n",
    "        help='Specifies whether to use the \\'evaluate\\' reward '\n",
    "             'for the environment.')\n",
    "    parser.add_argument(\n",
    "        '--render_mode',\n",
    "        type=str,\n",
    "        default='sumo_gui',\n",
    "        help='Pick the render mode. Options include sumo_web3d, '\n",
    "             'rgbd and sumo_gui')\n",
    "    parser.add_argument(\n",
    "        '--save_render',\n",
    "        action='store_true',\n",
    "        help='Saves a rendered video to a file. NOTE: Overrides render_mode '\n",
    "             'with pyglet rendering.')\n",
    "    parser.add_argument(\n",
    "        '--horizon',\n",
    "        type=int,\n",
    "        help='Specifies the horizon.')\n",
    "    parser.add_argument(\n",
    "        \"--randomize_vehicles\", default=True,\n",
    "        help=\"randomize the number of vehicles in the system and where they come from\",\n",
    "        action=\"store_true\")\n",
    "    \n",
    "    parser.add_argument('--grid_search', action='store_true', default=False,\n",
    "                        help='If true, a grid search is run')\n",
    "    parser.add_argument('--run_mode', type=str, default='local',\n",
    "                        help=\"Experiment run mode (local | cluster)\")\n",
    "    parser.add_argument('--algo', type=str, default='TD3',\n",
    "                        help=\"RL method to use (PPO, TD3, MADDPG)\")\n",
    "    parser.add_argument(\"--pedestrians\",\n",
    "                        help=\"use pedestrians, sidewalks, and crossings in the simulation\",\n",
    "                        action=\"store_true\")\n",
    "    \n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-17 20:52:06,713\tINFO resource_spec.py:212 -- Starting Ray with 9.96 GiB memory available for workers and up to 5.0 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-07-17 20:52:07,016\tINFO services.py:1170 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.12',\n",
       " 'raylet_ip_address': '192.168.1.12',\n",
       " 'redis_address': '192.168.1.12:55329',\n",
       " 'object_store_address': '/tmp/ray/session_2020-07-17_20-52-06_692229_73784/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-07-17_20-52-06_692229_73784/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-07-17_20-52-06_692229_73784'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = create_parser()\n",
    "args = parser.parse_args([os.path.expanduser(\"~/ray_results/final_policy_rss/DQN_0_0_2020-06-24_14-19-463mwnbpq0\"), \"400\"])\n",
    "ray.shutdown()\n",
    "ray.init(num_cpus=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.1)--(1.1) (1.1)--(1.2) 1 1\n",
      "(2.1)--(1.1) (1.1)--(1.2) 1 1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "run_transfer(args, imitation_model=False, is_discrete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_pair_vals = [[], []]\n",
    "\n",
    "for _ in range(3):\n",
    "    vals = list(run_transfer(args))\n",
    "    action_pair_vals[0].extend(vals[0])\n",
    "    action_pair_vals[1].extend(vals[1])\n",
    "    print(action_pair_vals)\n",
    "    \n",
    "action_pair_vals = np.array(action_pair_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.stack([action_pair_vals[0], action_pair_vals[1]])\n",
    "np.cov(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_pair_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(action_pair_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [[2.6, 2.6], [2.6, -0.1363802], [-0.1363802, 2.6], [2.6, -2.239944], [-2.239944, 0.11161637], [0.11161637, -4.5], [-4.5, -4.5], [-4.5, -4.190493], [-4.190493, -4.5], [-4.5, 0.22552395], [0.22552395, -4.5], [-4.5, -4.5], [-4.5, -4.5], [-4.5, -4.5], [-4.5, -4.5], [-4.5, -4.5], [-4.5, -4.5], [-4.5, -4.5], [-4.5, -4.5], [-4.5, -4.5], [-4.5, 2.1391077], [2.1391077, -4.5], [-4.5, -4.5], [-4.5, -4.5], [-4.5, -4.5], [-4.5, -4.5], [-4.5, -4.5], [-4.5, -4.5], [-4.5, -4.5], [-4.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian_traffic",
   "language": "python",
   "name": "bayesian_traffic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
