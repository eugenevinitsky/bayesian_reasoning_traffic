{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Use Nick's PPO trained policy to perform inference on whether there is a pedestrian or not\"\"\"\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import gym\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PyQt5\n",
    "import psutil\n",
    "\n",
    "import ray\n",
    "try:\n",
    "    from ray.rllib.agents.agent import get_agent_class\n",
    "except ImportError:\n",
    "    from ray.rllib.agents.registry import get_agent_class\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "# from flow.algorithms.maddpg.maddpg import DEFAULT_CONFIG as MADDPG_DEFAULT_CONFIG, MADDPGTrainer\n",
    "\n",
    "\n",
    "from flow.core.util import emission_to_csv\n",
    "from flow.utils.registry import make_create_env\n",
    "from flow.utils.rllib import get_flow_params\n",
    "from flow.utils.rllib import get_rllib_config\n",
    "from flow.utils.rllib import get_rllib_pkl\n",
    "\n",
    "from examples.rllib.multiagent_exps.test_predictor.pedestrian_policy_1 import create_env, create_agent\n",
    "from examples.rllib.multiagent_exps.bayesian_0_no_grid_env import make_flow_params as bayesian_1_flow_params\n",
    "\n",
    "EXAMPLE_USAGE = \"\"\"\n",
    "example usage:\n",
    "    python ./visualizer_rllib.py /ray_results/experiment_dir/result_dir 1\n",
    "Here the arguments are:\n",
    "1 - the path to the simulation results\n",
    "2 - the number of the checkpoint\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import ray\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=16619614208, available=13088047104, percent=21.2, used=2928435200, free=11149099008, active=3477258240, inactive=1509130240, buffers=350044160, cached=2192035840, shared=333336576, slab=223162368)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Math\n",
    "\n",
    "$$ p(c|a) = \\frac{f(a|c) p(c)}{M}, M = \\sum_{e \\in every} f(a | e) p(e), c \\text{ is some joint ped combination}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code flow\n",
    "\n",
    "e denotes an element within the 'every' set, where 'every' = the set of all possible pedestrian location combinations observable by a vehicle\n",
    "\n",
    "o denotes an element with the 'other' set, where 'other' = the set of all possible pedestrian location combinations observable by a vehicle, where $o_1 = 1$ or some other specific location has a fixed value.\n",
    " \n",
    "0. Fill up $p(e)$ with $\\frac{1}{3^4}$\n",
    "\n",
    "1. Fill up $f(a|e)$\n",
    "\n",
    "2. Compute $M = \\sum_{e \\in every} f(a|e) p(e)$\n",
    "\n",
    "3. Compute $p(e|a) = \\frac{f(a|e) p(e)}{M}$ \n",
    "\n",
    "4. Update $p(e) = p(e|a)$\n",
    "\n",
    "5. Compute $p(o_i = b_i | a) = \\sum_{o \\in other} p(o|a)$\n",
    "\n",
    "6. Store $p(o_i = b_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The keys 'ij' mean transition from state i to state j\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{0: {'00': 164579, '01': 107, '10': 107, '11': 14516}, \n",
    " 1: {'00': 163013, '01': 123, '10': 123, '11': 16050}, \n",
    " 2: {'00': 161202, '01': 134, '10': 134, '11': 17839}, \n",
    " 3: {'00': 164743, '01': 112, '10': 112, '11': 14342}}\n",
    "\n",
    "\"The keys 'ij' mean transition from state i to state j\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(ped_{t} | ped_{t-1}) = 14516 / (107 + 14516)\n",
    "\n",
    "p(ped_{t} | no_ped_{t-1}) = 107 / (107 + 164579)\n",
    "\n",
    "p(no_ped_{t} | ped_{t-1}) = 107 / (107 + 14516)\n",
    "\n",
    "p(no_ped_{t} | no_ped_{t-1}) = 164579 / (164579 + 107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = 14516 / (107 + 14516)\n",
    "pno = 107 / (107 + 164579)\n",
    "nop = 107 / (107 + 14516)\n",
    "nono = 164579 / (164579 + 107)\n",
    "\n",
    "a = np.array([nono, pno])\n",
    "b = np.array([nop, pp])\n",
    "TRANSITION_MATRIX = np.array([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Convert constants to uppercase\n",
    "K = 5\n",
    "ped_idx_lst = [5, 6, 7, 8]\n",
    "ped_front = ped_idx_lst[0]\n",
    "ped_back = ped_idx_lst[-1]\n",
    "\n",
    "num_locs = 4\n",
    "flag_set = (\"-1\", \"0\", \"1\")\n",
    "\n",
    "def run_env(env, agent, config, flow_params):\n",
    "    \"\"\"Run the simulation and control the rl car using the trained policy. \n",
    "    \n",
    "    observation[4:10] = ped_param\n",
    "    \n",
    "    The six binary grids are at indices 4 to 9 inclusive\n",
    "    \"\"\"\n",
    "    # set up relevant policy and env\n",
    "    if config.get('multiagent', {}).get('policies', None):\n",
    "        multiagent = True\n",
    "        rets = {}\n",
    "        # map the agent id to its policy\n",
    "        policy_map_fn = config['multiagent']['policy_mapping_fn']\n",
    "        for key in config['multiagent']['policies'].keys():\n",
    "            rets[key] = []\n",
    "    else:\n",
    "        multiagent = False\n",
    "        rets = []\n",
    "\n",
    "    if config['model']['use_lstm']:\n",
    "        use_lstm = True\n",
    "        if multiagent:\n",
    "            state_init = {}\n",
    "            policy_map_fn = config['multiagent']['policy_mapping_fn']\n",
    "            size = config['model']['lstm_cell_size']\n",
    "            for key in config['multiagent']['policies'].keys():\n",
    "                state_init[key] = [np.zeros(size, np.float32),\n",
    "                                   np.zeros(size, np.float32)]\n",
    "        else:\n",
    "            state_init = [\n",
    "                np.zeros(config['model']['lstm_cell_size'], np.float32),\n",
    "                np.zeros(config['model']['lstm_cell_size'], np.float32)\n",
    "            ]\n",
    "    else:\n",
    "        use_lstm = False\n",
    "\n",
    "    env.restart_simulation(\n",
    "        sim_params=flow_params['sim'], render=flow_params['sim'].render)    \n",
    "\n",
    "    binary_observations = False\n",
    "    \n",
    "    # Permutation lists\n",
    "    joint_ped_combos_str = all_ped_combos_strs(num_locs, flag_set)\n",
    "    joint_ped_combos_int_list = all_ped_combos_lsts(num_locs, flag_set)\n",
    "    single_ped_combs_str = single_ped_posteriors_strs(num_locs, flag_set)\n",
    "    \n",
    "    ################\n",
    "    # Dictionaries #\n",
    "    ################\n",
    "    \n",
    "    # 1\n",
    "    single_priors_fixed = {comb : [1 / len(flag_set)] for comb in single_ped_combs_str} \n",
    "    single_priors_updated = {comb : [1 / len(flag_set)] for comb in single_ped_combs_str}\n",
    "\n",
    "    # 2\n",
    "    joint_likelihood_densities = {comb : [] for comb in joint_ped_combos_str}\n",
    "    \n",
    "    # 3\n",
    "    joint_priors_fixed = {comb : [1 / (len(flag_set)**num_locs)] for comb in joint_ped_combos_str}\n",
    "    joint_priors_updated = {comb : [1 / (len(flag_set)**num_locs)] for comb in joint_ped_combos_str}\n",
    "    \n",
    "    # 5 \n",
    "    joint_posteriors_fixed = {comb : [] for comb in joint_ped_combos_str}\n",
    "    joint_posteriors_updated = {comb : [] for comb in joint_ped_combos_str}\n",
    "    \n",
    "    # 6 \n",
    "    single_posteriors_fixed = {comb : [] for comb in single_ped_combs_str}\n",
    "    single_posteriors_updated = {comb : [] for comb in single_ped_combs_str}\n",
    "    \n",
    "    \n",
    "    # 1 Filter\n",
    "    single_priors_filter = {comb : [1 / len(flag_set)] for comb in single_ped_combs_str}\n",
    "    \n",
    "    # 3 Filter\n",
    "    joint_priors_filter = {comb : [1 / (len(flag_set)**num_locs)] for comb in joint_ped_combos_str}\n",
    "\n",
    "    # 5 Filter\n",
    "    joint_posteriors_filter = {comb : [] for comb in joint_ped_combos_str}\n",
    "    \n",
    "    # 6 Filter\n",
    "    single_posteriors_filter = {comb : [] for comb in single_ped_combs_str} \n",
    "        \n",
    "    \n",
    "    # 5 Updated K\n",
    "    single_posteriors_updated_K = {comb : [] for comb in single_ped_combs_str}\n",
    "\n",
    "    visible_pedestrian_dct = {loc : [] for loc in range(num_locs)}\n",
    "    intersection_status = []\n",
    "\n",
    "    \n",
    "    ####################\n",
    "    # Step through env #\n",
    "    ####################\n",
    "    \n",
    "    for i in range(args.num_rollouts):\n",
    "        state = env.reset()\n",
    "        for _ in range(600):\n",
    "            vehicles = env.unwrapped.k.vehicle\n",
    "            pedestrian = env.unwrapped.k.pedestrian\n",
    "            if multiagent:                \n",
    "                action, logits = {}, {}\n",
    "                for agent_id in state.keys():\n",
    "                    if use_lstm:   # we don't use lstm\n",
    "                        action[agent_id], state_init[agent_id], logits = \\\n",
    "                            agent.compute_action(state[agent_id], state=state_init[agent_id], policy_id=policy_map_fn(agent_id))\n",
    "                    else:\n",
    "                        if state != {}:\n",
    "                            \n",
    "                            print(psutil.virtual_memory())\n",
    "                            \n",
    "                            # s_all = state the agent observes\n",
    "                            s_all = state[agent_id]\n",
    "                            # get ped visibility state array of length 6 from the rl car's POV\n",
    "                            s_ped = s_all[ped_idx_lst]\n",
    "\n",
    "                            # compute the actual action taken by the rl car\n",
    "                            action[agent_id], _, logit_actual = agent.compute_action(state[agent_id], policy_id=policy_map_fn(agent_id), full_fetch=True)    \n",
    "                            action_ = action[agent_id][0]\n",
    "\n",
    "                            # update the visible_pedestrian dict\n",
    "                            for idx, val in enumerate(s_ped):\n",
    "                                visible_pedestrian_dct[idx] = visible_pedestrian_dct[idx] + [val]\n",
    "\n",
    "                            # update rl car's intersection status\n",
    "                            rt = vehicles.get_route('rl_0')\n",
    "                            if vehicles.get_edge('rl_0') == rt[0]:\n",
    "                                intersection_status.append(-1)\n",
    "                            elif vehicles.get_edge('rl_0') == rt[-1]:\n",
    "                                intersection_status.append(1)\n",
    "                            else:\n",
    "                                intersection_status.append(0)\n",
    "\n",
    "                            # 2 f(a|e) # 4 M\n",
    "                            M_updated, M_fixed, M_filter = 0, 0, 0\n",
    "\n",
    "                            for str_comb, lst_comb in zip(joint_ped_combos_str, joint_ped_combos_int_list):\n",
    "\n",
    "                                s_all_modified = np.copy(s_all) # s_all_modified = hypothetical state that an agent observes\n",
    "                                s_all_modified[ped_front : ped_back + 1] = lst_comb\n",
    "                                _, _, logit = agent.compute_action(s_all_modified, policy_id=policy_map_fn(agent_id), full_fetch=True)\n",
    "\n",
    "                                mu, ln_sigma = logit['behaviour_logits']\n",
    "                                sigma = np.exp(ln_sigma)\n",
    "\n",
    "                                # f(a|e)\n",
    "                                joint_likelihood_density = accel_pdf(mu, sigma, action_)\n",
    "                                joint_likelihood_densities[str_comb] = joint_likelihood_densities[str_comb] + [joint_likelihood_density]\n",
    "\n",
    "                                # M\n",
    "                                # Get p(e)\n",
    "                                updated_prior = joint_priors_updated[str_comb][-1]\n",
    "                                fixed_prior = joint_priors_fixed[str_comb][-1]\n",
    "                                filtered_prior = joint_priors_filter[str_comb][-1]\n",
    "\n",
    "                                M_updated += joint_likelihood_density * updated_prior\n",
    "                                M_fixed += joint_likelihood_density * fixed_prior\n",
    "                                M_filter += joint_likelihood_density * filtered_prior\n",
    "\n",
    "                            # 5 p(e|a) joint posterior masses\n",
    "                            for str_comb in joint_ped_combos_str:\n",
    "                                # f(a|e)\n",
    "                                joint_likelihood_density = joint_likelihood_densities[str_comb][-1]\n",
    "                                # p(e)\n",
    "                                updated_prior = joint_priors_updated[str_comb][-1]\n",
    "                                fixed_prior = joint_priors_fixed[str_comb][-1]\n",
    "                                filtered_prior = joint_priors_filter[str_comb][-1]\n",
    "\n",
    "                                # p(e|a)\n",
    "                                joint_posterior_updated = joint_likelihood_density * updated_prior / M_updated\n",
    "                                joint_posterior_fixed = joint_likelihood_density * fixed_prior / M_fixed\n",
    "                                joint_posterior_filtered = joint_likelihood_density * filtered_prior / M_filter\n",
    "\n",
    "                                joint_posteriors_updated[str_comb] = joint_posteriors_updated[str_comb] + [joint_posterior_updated]\n",
    "                                joint_posteriors_fixed[str_comb] = joint_posteriors_fixed[str_comb] + [joint_posterior_fixed]\n",
    "                                joint_posteriors_filter[str_comb] = joint_posteriors_filter[str_comb] + [joint_posterior_filtered]\n",
    "\n",
    "                            # 6 & 7\n",
    "                            for loc_ in range(num_locs):\n",
    "                                for val_ in flag_set:\n",
    "\n",
    "                                    single_posterior_updated = 0\n",
    "                                    single_posterior_fixed = 0\n",
    "                                    single_posterior_filter = 0\n",
    "\n",
    "                                    for key in ped_combos_one_loc_fixed_strs(loc_, val_):\n",
    "                                        single_posterior_updated += joint_posteriors_updated[key][-1]\n",
    "                                        single_posterior_fixed += joint_posteriors_fixed[key][-1]\n",
    "                                        single_posterior_filter += joint_posteriors_filter[key][-1]\n",
    "\n",
    "                                    single_posterior_str = f'o_{loc_} = {val_}'\n",
    "\n",
    "                                    single_posteriors_updated[single_posterior_str] = single_posteriors_updated[single_posterior_str] + [single_posterior_updated]\n",
    "                                    \n",
    "                                    if len(joint_priors_updated[\"1 1 1 1\"]) < K: \n",
    "                                        single_posteriors_updated_K[single_posterior_str] = single_posteriors_updated_K[single_posterior_str] + [single_posterior_updated]\n",
    "                                   \n",
    "                                    single_posteriors_fixed[single_posterior_str] = single_posteriors_fixed[single_posterior_str] + [single_posterior_fixed]\n",
    "                                    single_posteriors_filter[single_posterior_str] = single_posteriors_filter[single_posterior_str] + [single_posterior_filter]\n",
    "                                    \n",
    "                                    # 7\n",
    "                                    single_priors_fixed[single_posterior_str] = single_priors_fixed[single_posterior_str] + [single_posterior_fixed]\n",
    "                                    single_priors_updated[single_posterior_str] = single_priors_updated[single_posterior_str] + [single_posterior_updated]\n",
    "                                    \n",
    "                            # FILTER (part after step 5: filter p(o|a))\n",
    "                            for loc_ in range(num_locs):\n",
    "                                val0, val1 = \"0\", \"1\"\n",
    "                                single_0 = f'o_{loc_} = {val0}'\n",
    "                                single_1 = f'o_{loc_} = {val1}'\n",
    "                                filtered = TRANSITION_MATRIX @ np.array([single_posteriors_filter[single_0][-1], single_posteriors_filter[single_1][-1]])\n",
    "                                single_posteriors_filter[single_0][-1], single_posteriors_filter[single_1][-1] = filtered[0], filtered[1]\n",
    "\n",
    "                           # 7 Filter Update single priors Pr(o_i | a) using posteriors\n",
    "                            for loc_ in range(num_locs):\n",
    "                                for val_ in flag_set:\n",
    "                                    single_prior_str = f'o_{loc_} = {val_}'\n",
    "                                    single_priors_filter[single_prior_str] += single_priors_filter[single_prior_str] + single_posteriors_filter[single_prior_str]\n",
    "\n",
    "                            # 8 Update joint priors p(o|a) = \\prod_{o_i \\in o} p(o_i)\n",
    "                            for str_comb in joint_ped_combos_str:\n",
    "                                new_joint_prior_updated = 1\n",
    "                                new_joint_prior_fixed = 1\n",
    "\n",
    "                                single_ped_lst = joint_ped_combo_str_to_single_ped_combo(str_comb)\n",
    "                                for single_ped in single_ped_lst:\n",
    "                                    new_joint_prior_updated *= single_posteriors_updated[single_ped][-1]\n",
    "\n",
    "                                joint_priors_updated[str_comb] = joint_priors_updated[str_comb] + [new_joint_prior_updated]\n",
    "\n",
    "                            # 8 FILTER Update joint priors p(o|a) = \\prod_{o_i \\in o} p(o_i)\n",
    "                            for str_comb in joint_ped_combos_str:\n",
    "                                new_joint_prior_filter = 1\n",
    "\n",
    "                                single_ped_lst = joint_ped_combo_str_to_single_ped_combo(str_comb)\n",
    "\n",
    "                                for single_ped in single_ped_lst:\n",
    "                                    new_joint_prior_filter *= single_priors_filter[single_ped][-1]\n",
    "\n",
    "                                joint_priors_filter[str_comb] = joint_priors_filter[str_comb] + [new_joint_prior_filter]\n",
    "    \n",
    "    \n",
    "                            ############            \n",
    "                            # K update #\n",
    "                            ############\n",
    "                \n",
    "                            if len(joint_likelihood_densities[\"1 1 1 1\"]) >= K:\n",
    "                                joint_priors_updated_K = {comb : [1 / (len(flag_set)**num_locs)] for comb in joint_ped_combos_str}\n",
    "\n",
    "                                for str_comb, lst_comb in zip(joint_ped_combos_str, joint_ped_combos_int_list):\n",
    "\n",
    "                                    s_all_modified = np.copy(s_all) # s_all_modified = hypothetical state that an agent observes\n",
    "                                    s_all_modified[ped_front : ped_back + 1] = lst_comb\n",
    "                                    _, _, logit = agent.compute_action(s_all_modified, policy_id=policy_map_fn(agent_id), full_fetch=True)\n",
    "\n",
    "                                    mu, ln_sigma = logit['behaviour_logits']\n",
    "                                    sigma = np.exp(ln_sigma)\n",
    "\n",
    "                                # update joint prior masses\n",
    "                                for i in reversed(range(K)):\n",
    "                                    M_updated_K = 0\n",
    "                                    for str_comb in joint_ped_combos_str:\n",
    "                                        M_updated_K += joint_likelihood_densities[str_comb][-1 - i] * joint_priors_updated_K[str_comb][-1]\n",
    "                                    for str_comb in joint_ped_combos_str:\n",
    "                                        joint_likelihood_density = joint_likelihood_densities[str_comb][-1 - i] # f(a|c)\n",
    "                                        joint_prior_updated = joint_priors_updated_K[str_comb][-1] # p(c)\n",
    "                \n",
    "                                        joint_priors_updated_K[str_comb] = joint_priors_updated_K[str_comb] + [joint_likelihood_density * joint_prior_updated / M_updated_K]\n",
    "                                    \n",
    "                                # 5 Compute single posteriors Pr(o_i = b_i | a)\n",
    "                                for loc__ in range(num_locs):\n",
    "                                    for val__ in flag_set:\n",
    "\n",
    "                                        single_posterior_updated = 0\n",
    "\n",
    "                                        for key in ped_combos_one_loc_fixed_strs(loc__, val__):\n",
    "                                            single_posterior_updated += joint_priors_updated_K[key][-1]\n",
    "\n",
    "                                        single_posterior_str = f'o_{loc__} = {val__}'\n",
    "                                        single_posteriors_updated_K[single_posterior_str] = single_posteriors_updated_K[single_posterior_str] + [single_posterior_updated]\n",
    "\n",
    "            else:\n",
    "                action = agent.compute_action(state)\n",
    "\n",
    "            state, reward, done, _ = env.step(action)\n",
    "\n",
    "            if multiagent and done['__all__']:\n",
    "                break\n",
    "            if not multiagent and done:\n",
    "\n",
    "                break    \n",
    "            state, reward, done, _ = env.step(action)   \n",
    "\n",
    "    visible_ped_lsts = [visible_pedestrian_dct[i] for i in range(num_locs)]\n",
    "    legends = [f'ped at loc {i}' for i in range(num_locs)]\n",
    "\n",
    "    for loc in range(num_locs):\n",
    "        val = 1\n",
    "        single_posterior_str = single_posterior_to_str(loc, val)\n",
    "        a_ = single_posteriors_updated[single_posterior_str]\n",
    "        b_ = single_posteriors_fixed[single_posterior_str]\n",
    "        c_ = single_posteriors_updated_K[single_posterior_str]\n",
    "        d_ = single_posteriors_filter[single_posterior_str]\n",
    "        plot_2_lines(a_, b_, [f'Pr(ped in grid {loc} = {val}) using updated priors K = all', f'Pr(ped in grid {loc} = {val}) using fixed priors'])\n",
    "        plot_2_lines(c_, b_, [f'Pr(ped in grid {loc} = {val}) using updated priors K = 5', f'Pr(ped in grid {loc} = {val}) using fixed priors'])\n",
    "        plot_2_lines(d_, b_, [f'Pr(ped in grid {loc} = {val}) using filtered priors', f'Pr(ped in grid {loc} = {val}) using fixed priors'])\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "    y0 = visible_pedestrian_dct[0]\n",
    "    y1 = visible_pedestrian_dct[1]\n",
    "    y2 = visible_pedestrian_dct[2]\n",
    "    y3 = visible_pedestrian_dct[3]\n",
    "\n",
    "    vis_ped_0 = plt.subplot(2, 3, 1)\n",
    "    plt.plot(y0, 'o-')\n",
    "    vis_ped_0.set_title('Pedestrian in loc 0')\n",
    "    vis_ped_0.set_xlabel('time (s)')\n",
    "    vis_ped_0.set_ylabel('in loc 1?')\n",
    "    vis_ped_0.set_ylim([-1, 1])\n",
    "\n",
    "    vis_ped_1 = plt.subplot(2, 3, 2)\n",
    "    plt.plot(y1, 'o-')\n",
    "    vis_ped_1.set_title('Pedestrian in loc 1')\n",
    "    vis_ped_1.set_xlabel('time (s)')\n",
    "    vis_ped_1.set_ylabel('in loc 1?')\n",
    "    vis_ped_1.set_ylim([-1, 1])\n",
    "\n",
    "    vis_ped_2 = plt.subplot(2, 3, 3)\n",
    "    vis_ped_2.plot(y2, '.-')\n",
    "    vis_ped_2.set_title('Pedestrian in loc 2')\n",
    "\n",
    "    vis_ped_2.set_xlabel('time (s)')\n",
    "    vis_ped_2.set_ylabel('in loc 2?')\n",
    "    vis_ped_2.set_ylim([-1, 1])\n",
    "\n",
    "\n",
    "    vis_ped_3 = plt.subplot(2, 3, 4)\n",
    "    vis_ped_3.plot(y3, '.-')\n",
    "    vis_ped_3.set_title('Pedestrian in loc 3')\n",
    "\n",
    "    vis_ped_3.set_xlabel('time (s)')\n",
    "    vis_ped_3.set_ylabel('in loc 3?')\n",
    "    vis_ped_3.set_ylim([-1, 1])\n",
    "\n",
    "\n",
    "    intersection = plt.subplot(2, 3, 5)\n",
    "    intersection.plot(intersection_status)\n",
    "    intersection.set_title('-1 = approaching, 0 = on intersection, 1 = past')\n",
    "    intersection.set_xlabel('time (s)')\n",
    "    intersection.set_ylabel('rl car location')\n",
    "    intersection.set_ylim([-1, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter commented out (not tidied u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Convert constants to uppercase\n",
    "K = 5\n",
    "ped_idx_lst = [5, 6, 7, 8]\n",
    "ped_front = ped_idx_lst[0]\n",
    "ped_back = ped_idx_lst[-1]\n",
    "\n",
    "num_locs = 4\n",
    "flag_set = (\"-1\", \"0\", \"1\")\n",
    "\n",
    "def run_env(env, agent, config, flow_params):\n",
    "    \"\"\"Run the simulation and control the rl car using the trained policy. \n",
    "    \n",
    "    observation[4:10] = ped_param\n",
    "    \n",
    "    The six binary grids are at indices 4 to 9 inclusive\n",
    "    \"\"\"\n",
    "    # set up relevant policy and env\n",
    "    if config.get('multiagent', {}).get('policies', None):\n",
    "        multiagent = True\n",
    "        rets = {}\n",
    "        # map the agent id to its policy\n",
    "        policy_map_fn = config['multiagent']['policy_mapping_fn']\n",
    "        for key in config['multiagent']['policies'].keys():\n",
    "            rets[key] = []\n",
    "    else:\n",
    "        multiagent = False\n",
    "        rets = []\n",
    "\n",
    "    if config['model']['use_lstm']:\n",
    "        use_lstm = True\n",
    "        if multiagent:\n",
    "            state_init = {}\n",
    "            policy_map_fn = config['multiagent']['policy_mapping_fn']\n",
    "            size = config['model']['lstm_cell_size']\n",
    "            for key in config['multiagent']['policies'].keys():\n",
    "                state_init[key] = [np.zeros(size, np.float32),\n",
    "                                   np.zeros(size, np.float32)]\n",
    "        else:\n",
    "            state_init = [\n",
    "                np.zeros(config['model']['lstm_cell_size'], np.float32),\n",
    "                np.zeros(config['model']['lstm_cell_size'], np.float32)\n",
    "            ]\n",
    "    else:\n",
    "        use_lstm = False\n",
    "\n",
    "    env.restart_simulation(\n",
    "        sim_params=flow_params['sim'], render=flow_params['sim'].render)    \n",
    "\n",
    "    binary_observations = False\n",
    "    \n",
    "    joint_ped_combos_str = all_ped_combos_strs(num_locs, flag_set)\n",
    "    joint_ped_combos_int_list = all_ped_combos_lsts(num_locs, flag_set)\n",
    "    single_ped_combs_str = single_ped_posteriors_strs(num_locs, flag_set)\n",
    "\n",
    "    # 1\n",
    "    single_priors_fixed = {comb : [1 / len(flag_set)] for comb in single_ped_combs_str} \n",
    "    single_priors_updated = {comb : [1 / len(flag_set)] for comb in single_ped_combs_str}\n",
    "    \n",
    "#     # 1 Filter\n",
    "#     single_priors_filter = {comb : [1 / len(flag_set)] for comb in single_ped_combs_str}\n",
    "    \n",
    "#     # 3 Filter\n",
    "#     joint_priors_filter = {comb : [1 / (len(flag_set)**num_locs)] for comb in joint_ped_combos_str}\n",
    "\n",
    "#     # 5 Filter\n",
    "#     joint_posteriors_filter = {comb : [] for comb in joint_ped_combos_str}\n",
    "    \n",
    "#     # 6 Filter\n",
    "#     single_posteriors_filter = {comb : [] for comb in single_ped_combs_str} \n",
    "\n",
    "    # 3\n",
    "    single_posteriors_fixed = {comb : [] for comb in single_ped_combs_str} \n",
    "    single_posteriors_updated = {comb : [] for comb in single_ped_combs_str} \n",
    "        \n",
    "    joint_priors_fixed = {comb : [1 / (len(flag_set)**num_locs)] for comb in joint_ped_combos_str}\n",
    "    joint_priors_updated = {comb : [1 / (len(flag_set)**num_locs)] for comb in joint_ped_combos_str}\n",
    "\n",
    "    # 2 Fill up joint_likelihood_densities dict f(a|e)\n",
    "    joint_likelihood_densities = {comb : [] for comb in joint_ped_combos_str}\n",
    "    \n",
    "    # 4 Compute M\n",
    "    \n",
    "    \n",
    "    # 5 Compute joint_posteriors p(e|a) [including the first prior]\n",
    "    joint_posteriors_fixed = {comb : [] for comb in joint_ped_combos_str}\n",
    "    joint_posteriors_updated = {comb : [] for comb in joint_ped_combos_str}\n",
    "\n",
    "    # 6 Compute single_posteriors p(e|a) by summing relevant joint posteriors\n",
    "    single_posteriors_fixed = {comb : [] for comb in single_ped_combs_str}\n",
    "    single_posteriors_updated = {comb : [] for comb in single_ped_combs_str}\n",
    "    \n",
    "    # 5 Compute single_posteriors p(e|a) by summing relevant joint posteriors\n",
    "    single_posteriors_updated_K = {comb : [] for comb in single_ped_combs_str}\n",
    "\n",
    "    # 6 Compute single_posteriors p(e|a) after filtering\n",
    "    single_posteriors_updated_filter = {comb : [] for comb in single_ped_combs_str}\n",
    "    \n",
    "    visible_pedestrian_dct = {loc : [] for loc in range(num_locs)}\n",
    "    intersection_status = []\n",
    "\n",
    "    for i in range(args.num_rollouts):\n",
    "        state = env.reset()\n",
    "        for _ in range(600):\n",
    "            vehicles = env.unwrapped.k.vehicle\n",
    "            pedestrian = env.unwrapped.k.pedestrian\n",
    "            if multiagent:                \n",
    "                action, logits = {}, {}\n",
    "                for agent_id in state.keys():\n",
    "                    if use_lstm:\n",
    "                        action[agent_id], state_init[agent_id], logits = \\\n",
    "                            agent.compute_action(state[agent_id], state=state_init[agent_id], policy_id=policy_map_fn(agent_id))\n",
    "                    else:\n",
    "                        if state != {}:\n",
    "                            print(psutil.virtual_memory())\n",
    "                            # s_all = state the agent observes\n",
    "                            s_all = state[agent_id]\n",
    "                            # get ped visibility state array of length 6 from the rl car's POV\n",
    "                            s_ped = s_all[ped_idx_lst]\n",
    "\n",
    "                            # compute the actual action taken by the rl car\n",
    "                            action[agent_id], _, logit_actual = agent.compute_action(state[agent_id], policy_id=policy_map_fn(agent_id), full_fetch=True)    \n",
    "                            action_ = action[agent_id][0]\n",
    "\n",
    "                            # update the visible_pedestrian dict\n",
    "                            for idx, val in enumerate(s_ped):\n",
    "                                visible_pedestrian_dct[idx] = visible_pedestrian_dct[idx] + [val]\n",
    "\n",
    "                            # update rl car's intersection status\n",
    "                            rt = vehicles.get_route('rl_0')\n",
    "                            if vehicles.get_edge('rl_0') == rt[0]:\n",
    "                                intersection_status.append(-1)\n",
    "                            elif vehicles.get_edge('rl_0') == rt[-1]:\n",
    "                                intersection_status.append(1)\n",
    "                            else:\n",
    "                                intersection_status.append(0)\n",
    "\n",
    "                            if True:\n",
    "                                # 2 compute joint likelihood densities f(a|e)\n",
    "                                # 4 M\n",
    "                                M_updated, M_fixed, M_filter = 0, 0, 0\n",
    "\n",
    "                                for str_comb, lst_comb in zip(joint_ped_combos_str, joint_ped_combos_int_list):\n",
    "\n",
    "                                    s_all_modified = np.copy(s_all) # s_all_modified = hypothetical state that an agent observes\n",
    "                                    s_all_modified[ped_front : ped_back + 1] = lst_comb\n",
    "                                    _, _, logit = agent.compute_action(s_all_modified, policy_id=policy_map_fn(agent_id), full_fetch=True)\n",
    "\n",
    "                                    mu, ln_sigma = logit['behaviour_logits']\n",
    "                                    sigma = np.exp(ln_sigma)\n",
    "\n",
    "                                    # f(a|e)\n",
    "                                    joint_likelihood_density = accel_pdf(mu, sigma, action_)\n",
    "                                    joint_likelihood_densities[str_comb] = joint_likelihood_densities[str_comb] + [joint_likelihood_density]\n",
    "\n",
    "                                    # M\n",
    "                                    # Get p(e)\n",
    "                                    updated_prior = joint_priors_updated[str_comb][-1]\n",
    "                                    fixed_prior = joint_priors_fixed[str_comb][-1]\n",
    "#                                     filtered_prior = joint_priors_filter[str_comb][-1]\n",
    "                                    \n",
    "                                    M_updated += joint_likelihood_density * updated_prior\n",
    "                                    M_fixed += joint_likelihood_density * fixed_prior\n",
    "#                                     M_filter += joint_likelihood_density * filtered_prior\n",
    "\n",
    "                                # 5 Compute p(e|a) joint posterior masses\n",
    "                                for str_comb in joint_ped_combos_str:\n",
    "                                    # f(a|e)\n",
    "                                    joint_likelihood_density = joint_likelihood_densities[str_comb][-1]\n",
    "                                    # p(e)\n",
    "                                    updated_prior = joint_priors_updated[str_comb][-1]\n",
    "                                    fixed_prior = joint_priors_fixed[str_comb][-1]\n",
    "#                                     filtered_prior = joint_priors_filter[str_comb][-1]\n",
    "\n",
    "                                    # p(e|a)\n",
    "                                    joint_posterior_updated = joint_likelihood_density * updated_prior / M_updated\n",
    "                                    joint_posterior_fixed = joint_likelihood_density * fixed_prior / M_fixed\n",
    "#                                     joint_posterior_filtered = joint_likelihood_density * filtered_prior / M_filter\n",
    "                                    \n",
    "                                    joint_posteriors_updated[str_comb] = joint_posteriors_updated[str_comb] + [joint_posterior_updated]\n",
    "                                    joint_posteriors_fixed[str_comb] = joint_posteriors_fixed[str_comb] + [joint_posterior_fixed]\n",
    "#                                     joint_posteriors_filter[str_comb] = joint_posteriors_filter[str_comb] + [joint_posterior_filtered]\n",
    "\n",
    "                                # 6 Compute single posteriors Pr(o_i | a)\n",
    "                                for loc_ in range(num_locs):\n",
    "                                    for val_ in flag_set:\n",
    "\n",
    "                                        single_posterior_updated = 0\n",
    "                                        single_posterior_fixed = 0\n",
    "                                        single_posterior_filter = 0\n",
    "\n",
    "                                        for key in ped_combos_one_loc_fixed_strs(loc_, val_):\n",
    "                                            single_posterior_updated += joint_posteriors_updated[key][-1]\n",
    "                                            single_posterior_fixed += joint_posteriors_fixed[key][-1]\n",
    "#                                             single_posterior_filter += joint_posteriors_filter[key][-1]\n",
    "                                            \n",
    "                                        single_posterior_str = f'o_{loc_} = {val_}'\n",
    "\n",
    "                                        single_posteriors_updated[single_posterior_str] = single_posteriors_updated[single_posterior_str] + [single_posterior_updated]\n",
    "                                        if len(joint_priors_updated[\"1 1 1 1\"]) < K: \n",
    "                                            single_posteriors_updated_K[single_posterior_str] = single_posteriors_updated_K[single_posterior_str] + [single_posterior_updated]\n",
    "                                        single_posteriors_fixed[single_posterior_str] = single_posteriors_fixed[single_posterior_str] + [single_posterior_fixed]\n",
    "#                                         single_posteriors_filter[single_posterior_str] = single_posteriors_filter[single_posterior_str] + [single_posterior_filter]\n",
    "                                # FILTER\n",
    "                                for loc_ in range(num_locs):\n",
    "                                    val0, val1 = \"0\", \"1\"\n",
    "                                    single_0 = f'o_{loc_} = {val0}'\n",
    "                                    single_1 = f'o_{loc_} = {val1}'\n",
    "#                                     filtered = TRANSITION_MATRIX @ np.array([single_posteriors_filter[single_0][-1], single_posteriors_filter[single_1][-1]])\n",
    "#                                     single_posteriors_filter[single_0][-1], single_posteriors_filter[single_1][-1] = filtered[0], filtered[1]\n",
    "\n",
    "#                                # 7 Filter Update single priors Pr(o_i | a) using posteriors\n",
    "#                                 for loc_ in range(num_locs):\n",
    "#                                     for val_ in flag_set:\n",
    "#                                         single_prior_str = f'o_{loc_} = {val_}'\n",
    "#                                         single_priors_filter[single_prior_str] += single_priors_filter[single_prior_str] + single_posteriors_filter[single_prior_str]\n",
    "                                        \n",
    "                                # 7 Update joint priors p(o|a) = \\prod_{o_i \\in o} p(o_i)\n",
    "                                for str_comb in joint_ped_combos_str:\n",
    "                                    new_joint_prior_updated = 1\n",
    "                                    new_joint_prior_fixed = 1\n",
    "\n",
    "                                    single_ped_lst = joint_ped_combo_str_to_single_ped_combo(str_comb)\n",
    "                                    for single_ped in single_ped_lst:\n",
    "                                        new_joint_prior_updated *= single_posteriors_updated[single_ped][-1]\n",
    "\n",
    "                                    joint_priors_updated[str_comb] = joint_priors_updated[str_comb] + [new_joint_prior_updated]\n",
    "    \n",
    "                                # 8 FILTER Update joint priors p(o|a) = \\prod_{o_i \\in o} p(o_i)\n",
    "                                for str_comb in joint_ped_combos_str:\n",
    "                                    new_joint_prior_filter = 1\n",
    "\n",
    "                                    single_ped_lst = joint_ped_combo_str_to_single_ped_combo(str_comb)\n",
    "                        \n",
    "                        ############ TODO KL #################\n",
    "#                                     for single_ped in single_ped_lst:\n",
    "#                                         new_joint_prior_filter *= single_priors_filter[single_ped][-1]\n",
    "\n",
    "#                                     joint_priors_filter[str_comb] = joint_priors_filter[str_comb] + [new_joint_prior_filter]\n",
    "    \n",
    "    \n",
    "                            ############            \n",
    "                            # K update #\n",
    "                            ############\n",
    "                \n",
    "                            if len(joint_likelihood_densities[\"1 1 1 1\"]) >= K:\n",
    "                                joint_priors_updated_K = {comb : [1 / (len(flag_set)**num_locs)] for comb in joint_ped_combos_str}\n",
    "\n",
    "                                for str_comb, lst_comb in zip(joint_ped_combos_str, joint_ped_combos_int_list):\n",
    "\n",
    "                                    s_all_modified = np.copy(s_all) # s_all_modified = hypothetical state that an agent observes\n",
    "                                    s_all_modified[ped_front : ped_back + 1] = lst_comb\n",
    "                                    _, _, logit = agent.compute_action(s_all_modified, policy_id=policy_map_fn(agent_id), full_fetch=True)\n",
    "\n",
    "                                    mu, ln_sigma = logit['behaviour_logits']\n",
    "                                    sigma = np.exp(ln_sigma)\n",
    "\n",
    "                                # update joint prior masses\n",
    "                                for i in reversed(range(K)):\n",
    "                                    M_updated_K = 0\n",
    "                                    for str_comb in joint_ped_combos_str:\n",
    "                                        M_updated_K += joint_likelihood_densities[str_comb][-1 - i] * joint_priors_updated_K[str_comb][-1]\n",
    "                                    for str_comb in joint_ped_combos_str:\n",
    "                                        joint_likelihood_density = joint_likelihood_densities[str_comb][-1 - i] # f(a|c)\n",
    "                                        joint_prior_updated = joint_priors_updated_K[str_comb][-1] # p(c)\n",
    "                \n",
    "                                        joint_priors_updated_K[str_comb] = joint_priors_updated_K[str_comb] + [joint_likelihood_density * joint_prior_updated / M_updated_K]\n",
    "                                    \n",
    "                                # 5 Compute single posteriors Pr(o_i = b_i | a)\n",
    "                                for loc__ in range(num_locs):\n",
    "                                    for val__ in flag_set:\n",
    "\n",
    "                                        single_posterior_updated = 0\n",
    "\n",
    "                                        for key in ped_combos_one_loc_fixed_strs(loc__, val__):\n",
    "                                            single_posterior_updated += joint_priors_updated_K[key][-1]\n",
    "\n",
    "                                        single_posterior_str = f'o_{loc__} = {val__}'\n",
    "                                        single_posteriors_updated_K[single_posterior_str] = single_posteriors_updated_K[single_posterior_str] + [single_posterior_updated]\n",
    "\n",
    "            else:\n",
    "                action = agent.compute_action(state)\n",
    "                \n",
    "            state, reward, done, _ = env.step(action)\n",
    "\n",
    "            if multiagent and done['__all__']:\n",
    "                break\n",
    "            if not multiagent and done:\n",
    "\n",
    "                break    \n",
    "            state, reward, done, _ = env.step(action)   \n",
    "\n",
    "        visible_ped_lsts = [visible_pedestrian_dct[i] for i in range(num_locs)]\n",
    "        legends = [f'ped at loc {i}' for i in range(num_locs)]\n",
    "\n",
    "        for loc in range(num_locs):\n",
    "            val = 1\n",
    "            single_posterior_str = single_posterior_to_str(loc, val)\n",
    "            a_ = single_posteriors_updated[single_posterior_str]\n",
    "            b_ = single_posteriors_fixed[single_posterior_str]\n",
    "            c_ = single_posteriors_updated_K[single_posterior_str]\n",
    "#             d_ = single_posteriors_filter[single_posterior_str]\n",
    "            plot_2_lines(a_, b_, [f'Pr(ped in grid {loc} = {val}) using updated priors K = all', f'Pr(ped in grid {loc} = {val}) using fixed priors'])\n",
    "            plot_2_lines(c_, b_, [f'Pr(ped in grid {loc} = {val}) using updated priors K = 5', f'Pr(ped in grid {loc} = {val}) using fixed priors'])\n",
    "#             plot_2_lines(d_, b_, [f'Pr(ped in grid {loc} = {val}) using filtered priors', f'Pr(ped in grid {loc} = {val}) using fixed priors'])\n",
    "\n",
    "        fig = plt.figure(figsize=(15, 15))\n",
    "        \n",
    "        y0 = visible_pedestrian_dct[0]\n",
    "        y1 = visible_pedestrian_dct[1]\n",
    "        y2 = visible_pedestrian_dct[2]\n",
    "        y3 = visible_pedestrian_dct[3]\n",
    "\n",
    "        vis_ped_0 = plt.subplot(2, 3, 1)\n",
    "        plt.plot(y0, 'o-')\n",
    "        vis_ped_0.set_title('Pedestrian in loc 0')\n",
    "        vis_ped_0.set_xlabel('time (s)')\n",
    "        vis_ped_0.set_ylabel('in loc 1?')\n",
    "        vis_ped_0.set_ylim([-1, 1])\n",
    "        \n",
    "        vis_ped_1 = plt.subplot(2, 3, 2)\n",
    "        plt.plot(y1, 'o-')\n",
    "        vis_ped_1.set_title('Pedestrian in loc 1')\n",
    "        vis_ped_1.set_xlabel('time (s)')\n",
    "        vis_ped_1.set_ylabel('in loc 1?')\n",
    "        vis_ped_1.set_ylim([-1, 1])\n",
    "\n",
    "        vis_ped_2 = plt.subplot(2, 3, 3)\n",
    "        vis_ped_2.plot(y2, '.-')\n",
    "        vis_ped_2.set_title('Pedestrian in loc 2')\n",
    "\n",
    "        vis_ped_2.set_xlabel('time (s)')\n",
    "        vis_ped_2.set_ylabel('in loc 2?')\n",
    "        vis_ped_2.set_ylim([-1, 1])\n",
    "\n",
    "        \n",
    "        vis_ped_3 = plt.subplot(2, 3, 4)\n",
    "        vis_ped_3.plot(y3, '.-')\n",
    "        vis_ped_3.set_title('Pedestrian in loc 3')\n",
    "\n",
    "        vis_ped_3.set_xlabel('time (s)')\n",
    "        vis_ped_3.set_ylabel('in loc 3?')\n",
    "        vis_ped_3.set_ylim([-1, 1])\n",
    "        \n",
    "        \n",
    "        intersection = plt.subplot(2, 3, 5)\n",
    "        intersection.plot(intersection_status)\n",
    "        intersection.set_title('-1 = approaching, 0 = on intersection, 1 = past')\n",
    "        intersection.set_xlabel('time (s)')\n",
    "        intersection.set_ylabel('rl car location')\n",
    "        intersection.set_ylim([-1, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String and permutation helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_ped_combo_str_to_single_ped_combo(joint_ped_combo_str):\n",
    "    \"\"\"Given a string of format '0 1 0 -1', return a list of all relevant single ped strings\n",
    "    i.e ['o_0 = 0', 'o_1 = 1', 'o_2 = 0', 'o_3 = -1']\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    jnt_ped_list = joint_ped_combo_str.split(\" \")\n",
    "    for loc, val in enumerate(jnt_ped_list):\n",
    "        res.append(single_posterior_to_str(loc, val))\n",
    "    return res\n",
    "\n",
    "def single_posterior_to_str(loc, val):\n",
    "    return f'o_{loc} = {val}'\n",
    "\n",
    "def all_ped_combos_strs(num_locs=4, val_set=(\"-1\", \"0\", \"1\")):\n",
    "    \"\"\"Return a list of all pedestrian observation combinations (in string format) for a vehicle under the 4 location scheme\"\"\"\n",
    "    res = []\n",
    "    lsts = all_ped_combos_lsts(num_locs, val_set)\n",
    "    for lst in lsts:\n",
    "        res.append(\" \".join(lst))\n",
    "    return res\n",
    "\n",
    "def all_ped_combos_lsts(num_locs=4, val_set=(\"-1\", \"0\", \"1\")):\n",
    "    \"\"\"Return a list of all pedestrian observation combinations (in list format) for a vehicle under the 4 location scheme\"\"\"\n",
    "    res = []\n",
    "    if num_locs == 0:\n",
    "        return []\n",
    "    if num_locs == 1:\n",
    "        return [[flag] for flag in val_set]\n",
    "\n",
    "    for comb in all_ped_combos_lsts(num_locs - 1, val_set):\n",
    "        # append a flag for all possible flags\n",
    "        for flag in val_set:\n",
    "            appended = comb + [flag]\n",
    "            res.append(appended)\n",
    "            \n",
    "    return res\n",
    "\n",
    "def ped_combos_one_loc_fixed_strs(fixed_loc, fixed_val, num_locs=4, val_set=(\"-1\", \"0\", \"1\")):\n",
    "    \"\"\"Return a list of all ped observation combs for a vehicle under the 4 location scheme\n",
    "    SUBJECT TO fixed_loc == fix_val\n",
    "    \n",
    "    This is handy for summation selection in equation (4) of the derivation\n",
    "    \n",
    "    @Parameters\n",
    "    fixed_loc: int\n",
    "        location from 0, 1, 2, 3\n",
    "    fixed_val: int\n",
    "        location from -1, 0, 1\n",
    "    \"\"\"    \n",
    "    res = []\n",
    "    lsts = ped_combos_one_loc_fixed_lsts(fixed_loc, fixed_val, num_locs, val_set)\n",
    "    for lst in lsts:\n",
    "        res.append(\" \".join(lst))\n",
    "    return res\n",
    "\n",
    "def ped_combos_one_loc_fixed_lsts(fixed_loc, fixed_val, num_locs=4, val_set=(\"-1\", \"0\", \"1\")):\n",
    "    \"\"\"Return a list of all ped observation combs for a vehicle under the 4 location scheme\n",
    "    SUBJECT TO fixed_loc == fix_val\n",
    "    \n",
    "    This is handy for summation selection in equation (4) of the derivation\n",
    "    \n",
    "    @Parameters\n",
    "    fixed_loc: int\n",
    "        location from 0, 1, 2, 3\n",
    "    fixed_val: int\n",
    "        location from -1, 0, 1\n",
    "    \"\"\"\n",
    "    fixed_val = str(fixed_val)\n",
    "    assert fixed_loc < num_locs and (fixed_val in val_set or str(fixed_val) in val_set)\n",
    "    \n",
    "    res = []\n",
    "    for comb in all_ped_combos_lsts(num_locs - 1, val_set):\n",
    "        # insert fixed val at correct position\n",
    "        left = comb[:fixed_loc]\n",
    "        right = comb[fixed_loc:]\n",
    "        res.append(left + [fixed_val] + right)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def single_cond_prob_to_str(grid_idx, val, num_indices = 6):\n",
    "    \"\"\"Generate the string representing the probability:\n",
    "    \n",
    "    Pr(o_i = val)\n",
    "    \n",
    "    ex:\n",
    "    For Pr(o_2 = 1), we'd have the string '21'\n",
    "    NB we're 1-indexing here\n",
    "    \"\"\"\n",
    "    assert grid_idx >= 1 and grid_idx <= num_indices\n",
    "    return str(grid_idx) + str(val)\n",
    "\n",
    "# better name for this? \n",
    "def ped_combos_for_single_cond_prob(grid_idx, val, output_len=6):\n",
    "    \"\"\"Helper function for computing a 'single' conditional probability e.g. p(o_3 = 1 | action)\n",
    "    Returns a list of pedestrian combinations to sum over to get the single conditional probability.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    grid_idx: int from 1 to 6 representing the grid cell we're considering\n",
    "    val: 0 or 1: 0 means no ped in the grid; 1 means ped in the grid\n",
    "    \n",
    "    3:0 means we want p(o_3 = 0 | a)\n",
    "    Therefore, we can get the list of all possible length 5 bitstrings, and stitch '0' in the correct place.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of bit strings of length 6\n",
    "    \"\"\"\n",
    "    \n",
    "    assert grid_idx >= 1 and grid_idx <= output_len\n",
    "    res = []\n",
    "    res_lst = make_permutations(output_len - 1, 2)\n",
    "    \n",
    "    for perm in res_lst:\n",
    "        res.append(str(perm[:grid_idx - 1:] + str(val) + perm[grid_idx - 1:]))\n",
    "        \n",
    "    return res\n",
    "\n",
    "def initial_prior_probs(num_digits=4, vals_per_dig=2):\n",
    "    \"\"\"Returns a dict with values of all permutations of bitstrings of length num_digits. \n",
    "    Each digit can take a value from 0 to (vals_per_dig - 1)\"\"\"\n",
    "    uniform_prob = 1 / (vals_per_dig ** num_digits)\n",
    "    res = make_dct_of_lsts(num_digits, vals_per_dig)\n",
    "    for key in res.keys():\n",
    "        res[key] = res[key] + [uniform_prob]\n",
    "    return res\n",
    "\n",
    "def make_dct_of_lsts(num_digits=4, vals_per_dig=2):\n",
    "    \"\"\"Return a dict with keys of bitstrings and values as empty lists. \n",
    "    Hardcoded for binary vals per var.\"\"\"\n",
    "    res = {}\n",
    "    lst_of_bitstrings = make_permutations(num_digits, vals_per_dig)\n",
    "        \n",
    "    return {str_ : [] for str_ in lst_of_bitstrings}\n",
    "\n",
    "def make_permutations(num_digits, vals_per_dig=2):\n",
    "    \"\"\"Make all permutations for a bit string of length num_digits\n",
    "    and vals_per_dig values per digit. Hardcoded for work for binary vals per var\"\"\"\n",
    "    if num_digits == 1:\n",
    "        return [str(i) for i in range(vals_per_dig)]\n",
    "    else:\n",
    "        small_perms = make_permutations(num_digits - 1, vals_per_dig)\n",
    "        # hardcoded for work for binary vals per var\n",
    "        return ['0' + bit_str for bit_str in small_perms] + ['1' + bit_str for bit_str in small_perms]\n",
    "    \n",
    "def single_ped_posteriors_strs(num_variables=4, val_set=(\"-1\", \"0\", \"1\")):\n",
    "    \"\"\"\n",
    "    @Params\n",
    "    num_variables = number of ped locations\n",
    "    \n",
    "    @Returns\n",
    "    list of strings. Strings have the format: 'o_{i}={val}', where val is in val_set\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(num_variables):\n",
    "        for flag in val_set:\n",
    "            res.append(f'o_{i} = {flag}')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accel_pdf(mu, sigma, actual):\n",
    "    \"\"\"Return pdf evaluated at actual acceleration\"\"\"\n",
    "    coeff = 1 / np.sqrt(2 * np.pi * (sigma**2))\n",
    "    exp = -0.5 * ((actual - mu) / sigma)**2\n",
    "    return coeff * np.exp(exp)\n",
    "\n",
    "def run_transfer(args):\n",
    "    # run transfer on the bayesian 1 env first\n",
    "    bayesian_0_params = bayesian_1_flow_params(args, pedestrians=True, render=True)\n",
    "#     import ipdb; ipdb.set_trace()\n",
    "    env, env_name = create_env(args, bayesian_0_params)\n",
    "    agent, config = create_agent(args, flow_params=bayesian_0_params)\n",
    "    run_env(env, agent, config, bayesian_0_params)\n",
    "\n",
    "def plot_2_lines(y1, y2, legend, viewable_ped=False):\n",
    "    x = np.arange(len(y1))\n",
    "    plt.plot(x, y1)\n",
    "    plt.plot(x, y2)\n",
    "    if viewable_ped:\n",
    "        plt.plot(x, viewable_ped)\n",
    "    plt.legend(legend, bbox_to_anchor=(0.5, 1.05), loc=3, borderaxespad=0.)\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)\n",
    "    \n",
    "def plot_lines(y_val_lsts, legends):\n",
    "    assert len(y_val_lsts) == len(legends)\n",
    "    x = np.arange(len(y_val_lsts[0]))\n",
    "    for y_vals in y_val_lsts:\n",
    "        plt.plot(x, y_vals)\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "\n",
    "    plt.legend(legends, bbox_to_anchor=(0.5, 1.05), loc=3, borderaxespad=0.)\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)\n",
    "    \n",
    "def create_parser():\n",
    "    \"\"\"Create the parser to capture CLI arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "        description='[Flow] Evaluates a reinforcement learning agent '\n",
    "                    'given a checkpoint.',\n",
    "        epilog=EXAMPLE_USAGE)\n",
    "\n",
    "    # required input parameters\n",
    "    parser.add_argument(\n",
    "        'result_dir', type=str, help='Directory containing results')\n",
    "    parser.add_argument('checkpoint_num', type=str, help='Checkpoint number.')\n",
    "\n",
    "    # optional input parameters\n",
    "    parser.add_argument(\n",
    "        '--run',\n",
    "        type=str,\n",
    "        help='The algorithm or model to train. This may refer to '\n",
    "             'the name of a built-on algorithm (e.g. RLLib\\'s DQN '\n",
    "             'or PPO), or a user-defined trainable function or '\n",
    "             'class registered in the tune registry. '\n",
    "             'Required for results trained with flow-0.2.0 and before.')\n",
    "    parser.add_argument(\n",
    "        '--num_rollouts',\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help='The number of rollouts to visualize.')\n",
    "    parser.add_argument(\n",
    "        '--gen_emission',\n",
    "        action='store_true',\n",
    "        help='Specifies whether to generate an emission file from the '\n",
    "             'simulation')\n",
    "    parser.add_argument(\n",
    "        '--evaluate',\n",
    "        action='store_true',\n",
    "        help='Specifies whether to use the \\'evaluate\\' reward '\n",
    "             'for the environment.')\n",
    "    parser.add_argument(\n",
    "        '--render_mode',\n",
    "        type=str,\n",
    "        default='sumo_gui',\n",
    "        help='Pick the render mode. Options include sumo_web3d, '\n",
    "             'rgbd and sumo_gui')\n",
    "    parser.add_argument(\n",
    "        '--save_render',\n",
    "        action='store_true',\n",
    "        help='Saves a rendered video to a file. NOTE: Overrides render_mode '\n",
    "             'with pyglet rendering.')\n",
    "    parser.add_argument(\n",
    "        '--horizon',\n",
    "        type=int,\n",
    "        help='Specifies the horizon.')\n",
    "    \n",
    "    parser.add_argument('--grid_search', action='store_true', default=False,\n",
    "                        help='If true, a grid search is run')\n",
    "    parser.add_argument('--run_mode', type=str, default='local',\n",
    "                        help=\"Experiment run mode (local | cluster)\")\n",
    "    parser.add_argument('--algo', type=str, default='TD3',\n",
    "                        help=\"RL method to use (PPO, TD3, MADDPG)\")\n",
    "    parser.add_argument(\"--pedestrians\",\n",
    "                        help=\"use pedestrians, sidewalks, and crossings in the simulation\",\n",
    "                        action=\"store_true\")\n",
    "    \n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-24 23:28:18,942\tWARNING services.py:597 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2020-05-24 23:28:18,943\tINFO resource_spec.py:216 -- Starting Ray with 6.1 GiB memory available for workers and up to 3.07 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: With render mode sumo_gui, an extra instance of the SUMO GUI will display before the GUI for visualizing the result. Click the green Play arrow to continue.\n",
      "(2.1)--(1.1) (1.1)--(1.2) 1 1\n",
      "Error making env  Cannot re-register id: Bayesian0NoGridEnv-v0\n",
      "True\n",
      "NOTE: With render mode sumo_gui, an extra instance of the SUMO GUI will display before the GUI for visualizing the result. Click the green Play arrow to continue.\n",
      "(2.1)--(1.1) (1.1)--(1.2) 1 1\n",
      "Error making env  Cannot re-register id: Bayesian0NoGridEnv-v0\n",
      "True\n",
      "(2.1)--(1.1) (1.1)--(1.2) 1 1\n",
      "Error making env  Cannot re-register id: Bayesian0NoGridEnv-v0\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-24 23:28:26,000\tWARNING util.py:45 -- Install gputil for GPU system monitoring.\n",
      "2020-05-24 23:28:26,059\tINFO trainable.py:346 -- Restored from checkpoint: /home/thankyou-always/TODO/research/bayesian_reasoning_traffic/ultimate_4ped_98/checkpoint_500/checkpoint-500\n",
      "2020-05-24 23:28:26,059\tINFO trainable.py:353 -- Current state after restoring: {'_iteration': 500, '_timesteps_total': 4063446, '_time_total': 50375.97657132149, '_episodes_total': 11533}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmem(total=16619614208, available=11008225280, percent=33.8, used=5042413568, free=10103308288, active=4374962176, inactive=1544712192, buffers=184115200, cached=1289777152, shared=333500416, slab=206135296)\n",
      "svmem(total=16619614208, available=11010035712, percent=33.8, used=5042999296, free=10105106432, active=4375322624, inactive=1542303744, buffers=184115200, cached=1287393280, shared=331104256, slab=206266368)\n",
      "svmem(total=16619614208, available=11010002944, percent=33.8, used=5043032064, free=10105073664, active=4375203840, inactive=1542303744, buffers=184115200, cached=1287393280, shared=331104256, slab=206258176)\n",
      "svmem(total=16619614208, available=11012931584, percent=33.7, used=5043032064, free=10108002304, active=4375203840, inactive=1539375104, buffers=184115200, cached=1284464640, shared=328175616, slab=206258176)\n",
      "svmem(total=16619614208, available=11011932160, percent=33.7, used=5044224000, free=10106990592, active=4376940544, inactive=1539194880, buffers=184254464, cached=1284145152, shared=327995392, slab=206258176)\n",
      "svmem(total=16619614208, available=11027230720, percent=33.6, used=5028913152, free=10122166272, active=4363751424, inactive=1539194880, buffers=184254464, cached=1284280320, shared=327995392, slab=206258176)\n",
      "svmem(total=16619614208, available=11027140608, percent=33.6, used=5029015552, free=10122055680, active=4363980800, inactive=1539198976, buffers=184254464, cached=1284288512, shared=327995392, slab=206258176)\n",
      "svmem(total=16619614208, available=11026616320, percent=33.7, used=5029539840, free=10121531392, active=4364783616, inactive=1539198976, buffers=184254464, cached=1284288512, shared=327995392, slab=206229504)\n",
      "svmem(total=16619614208, available=11026620416, percent=33.7, used=5029535744, free=10121539584, active=4364599296, inactive=1539194880, buffers=184254464, cached=1284284416, shared=327995392, slab=206229504)\n",
      "svmem(total=16619614208, available=11027062784, percent=33.7, used=5029072896, free=10121965568, active=4364251136, inactive=1539194880, buffers=184254464, cached=1284321280, shared=327995392, slab=206262272)\n",
      "svmem(total=16619614208, available=11032387584, percent=33.6, used=5023748096, free=10127290368, active=4358926336, inactive=1539194880, buffers=184254464, cached=1284321280, shared=327995392, slab=206262272)\n",
      "svmem(total=16619614208, available=11032997888, percent=33.6, used=5023137792, free=10127900672, active=4358254592, inactive=1539194880, buffers=184254464, cached=1284321280, shared=327995392, slab=206262272)\n",
      "svmem(total=16619614208, available=11033280512, percent=33.6, used=5022896128, free=10128142336, active=4357955584, inactive=1539231744, buffers=184254464, cached=1284321280, shared=327995392, slab=206262272)\n",
      "svmem(total=16619614208, available=11032506368, percent=33.6, used=5023670272, free=10127368192, active=4358762496, inactive=1539231744, buffers=184254464, cached=1284321280, shared=327995392, slab=206262272)\n",
      "svmem(total=16619614208, available=11032506368, percent=33.6, used=5023670272, free=10127368192, active=4358762496, inactive=1539231744, buffers=184254464, cached=1284321280, shared=327995392, slab=206262272)\n",
      "svmem(total=16619614208, available=11032240128, percent=33.6, used=5023936512, free=10127101952, active=4358807552, inactive=1539231744, buffers=184254464, cached=1284321280, shared=327995392, slab=206262272)\n",
      "svmem(total=16619614208, available=11032248320, percent=33.6, used=5023928320, free=10127110144, active=4358807552, inactive=1539231744, buffers=184262656, cached=1284313088, shared=327995392, slab=206262272)\n",
      "svmem(total=16619614208, available=11013160960, percent=33.7, used=5043015680, free=10108014592, active=4378329088, inactive=1539231744, buffers=184262656, cached=1284321280, shared=327995392, slab=206262272)\n",
      "svmem(total=16619614208, available=10969808896, percent=34.0, used=5086367744, free=10064662528, active=4421783552, inactive=1539231744, buffers=184262656, cached=1284321280, shared=327995392, slab=206262272)\n",
      "svmem(total=16619614208, available=10865057792, percent=34.6, used=5191254016, free=9959378944, active=4526780416, inactive=1539764224, buffers=184270848, cached=1284710400, shared=327995392, slab=206262272)\n",
      "svmem(total=16619614208, available=10654498816, percent=35.9, used=5401812992, free=9748819968, active=4737499136, inactive=1539764224, buffers=184270848, cached=1284710400, shared=327995392, slab=206262272)\n",
      "svmem(total=16619614208, available=10358820864, percent=37.7, used=5696913408, free=9452969984, active=5031395328, inactive=1539796992, buffers=184811520, cached=1284919296, shared=327995392, slab=206262272)\n",
      "svmem(total=16619614208, available=9830883328, percent=40.8, used=6225244160, free=8924315648, active=5559652352, inactive=1540071424, buffers=184811520, cached=1285242880, shared=327995392, slab=206295040)\n",
      "svmem(total=16619614208, available=8622571520, percent=48.1, used=7433842688, free=7715966976, active=6762508288, inactive=1539854336, buffers=184827904, cached=1284976640, shared=327741440, slab=206295040)\n",
      "svmem(total=16619614208, available=6200606720, percent=62.7, used=9859293184, free=5293977600, active=9182756864, inactive=1536401408, buffers=184827904, cached=1281515520, shared=324280320, slab=206295040)\n"
     ]
    }
   ],
   "source": [
    "parser = create_parser()\n",
    "args = parser.parse_args([\"/home/thankyou-always/TODO/research/bayesian_reasoning_traffic/ultimate_4ped_98\", \"500\"])\n",
    "ray.shutdown()\n",
    "ray.init(num_cpus=1)\n",
    "run_transfer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow3.7",
   "language": "python",
   "name": "flow3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
