{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-654e5c1ff7a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('bayesian_0_train.csv', header=None)\n",
    "df_test = pd.read_csv('bayesian_0_train.csv', header=None)\n",
    "\n",
    "# split train data into training and validation sets\n",
    "num_training = 30000\n",
    "\n",
    "# separate data into inputs and outputs for train, val and test sets\n",
    "train_labels = df_train.iloc[:num_training, 0]\n",
    "train_input_data = df_train.iloc[:num_training, 1:]\n",
    "val_labels = df_train.iloc[num_training:, 0]\n",
    "val_input_data = df_train.iloc[num_training:, 1:]\n",
    "test_labels = df_test.iloc[:, 0]\n",
    "test_input_data = df_test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianDataSet(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor, transforms=None):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "train_data = Bayesian0DataSet(train_input_data, train_labels, transform)\n",
    "val_data = Bayesian0DataSet(val_input_data, train_labels, transform)\n",
    "test_data = Bayesian0DataSet(test_input_data, test_labels, transform)\n",
    " \n",
    "# dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do I even check if this works? print it out!\n",
    "\n",
    "class BayesianDataSet(Dataset):\n",
    "    def __init__(self, inputs, labels=None, transforms=None):\n",
    "        self.X = inputs\n",
    "        self.y = label\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.X))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        input_vec = self.X.iloc[i, :]\n",
    "        data = np.asarray(input_vec).astype(np.uint8)\n",
    "        \n",
    "        if self.transforms:\n",
    "            input_vec = self.transforms(data)\n",
    "            \n",
    "        return (input_vec, self.y[i])\n",
    "\n",
    "train_data = Bayesian0DataSet(train_input_data, train_labels, transform)\n",
    "val_data = Bayesian0DataSet(val_input_data, train_labels, transform)\n",
    "test_data = Bayesian0DataSet(test_input_data, test_labels, transform)\n",
    " \n",
    "# dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=in_features, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=2)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "in_features = 17\n",
    "net = Net().to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0. ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2])\n",
    "u = np.array([2, 2])\n",
    "\n",
    "(2-x)/u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_log_likelihood(mean, sigma, target):\n",
    "    ## 1. should the inputs be tensors?\n",
    "    ## 2. should I be outputting the negative of ll?\n",
    "    \n",
    "\n",
    "    # convert input numpy arrays to tensors\n",
    "    mean = torch.from_numpy(mean)\n",
    "    sigma = torch.from_numpy(sigma)\n",
    "    target = torch.from_numpy(target)\n",
    "\n",
    "    return -0.5 * np.log(2 * np.pi * sigma**2) - ((target - mean) / sigma)**2\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "criterion = gaussian_log_likelihood()\n",
    "\n",
    "# Not 100% what return type this criterion guy should be ... docs have it as a class and then yield the result in \n",
    "# a forward() method\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, NUM_EPOCHS=10):\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        for data in train_loader:\n",
    "            input_vec, label = data[0], data[1]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, label)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print('[Epoch %d] loss: %.3f' %\n",
    "                    (epoch + 1, running_loss/len(trainloader)))\n",
    " \n",
    "    print('Done Training')\n",
    "\n",
    "def train(net, test_loader):\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            input_vec, label = data[0], data[1]\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, label)\n",
    "\n",
    "\n",
    "    print('Total loss of the network on test input dat: %0.3f %%' % (\n",
    "        total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net, train_loader)\n",
    "test(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow3.7",
   "language": "python",
   "name": "flow3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
